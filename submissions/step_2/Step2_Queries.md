
## Advance query

```json
{
  "search": "*",
  "top": 2,
  "count": true,
  "select": "content"
}
```

## Response

```json
{
  "@odata.context": "https://binhna-cogsearch.search.windows.net/indexes('azureblob-index')/$metadata#docs(*)",
  "@odata.count": 20,
  "value": [
    {
      "@search.score": 1,
      "content": "\nContext‑aware rule learning \nfrom smartphone data: survey, challenges \nand future directions\nIqbal H. Sarker1,2*\n\nIntroduction\nIn recent days, smartphones have become an essential part of our daily life and con-\nsidered as highly personal devices of individuals. These devices are also known as one \nof the most important IoT (Internet of Things) devices, because of their capabilities \nto interconnect their users with the Internet, and corresponding data processing [1]. \nSmartphones are also considered as “next generation, multifunctional cell phones that \nfacilitates data processing as well as enhanced wireless connectivity” [2]. The cellular net-\nwork coverage has reached 96.8% of the world population, and this number even reaches \n100% of the population in the developed countries [3]. In recent statistics, according to \nGoogle Trends [4] we have shown in Fig.  1, that users’ interest on “Mobile Phones” is \nmore and more than other platforms like “Desktop Computer”, “Laptop Computer” or \n\nAbstract \n\nSmartphones are considered as one of the most essential and highly personal devices \nof individuals in our current world. Due to the popularity of context-aware technol-\nogy and recent developments in smartphones, these devices can collect and process \nraw contextual data about users’ surrounding environment and their corresponding \nbehavioral activities with their phones. Thus, smartphone data analytics and building \ndata-driven context-aware systems have gained wide attention from both academia \nand industry in recent days. In order to build intelligent context-aware applications on \nsmartphones, effectively learning a set of context-aware rules from smartphone data \nis the key. This requires advanced data analytical techniques with high precision and \nintelligent decision making strategies based on contexts. In comparison to traditional \napproaches, machine learning based techniques provide more effective and efficient \nresults for smartphone data analytics and corresponding context-aware rule learning. \nThus, this article first makes a survey on previous work in the area of contextual smart-\nphone data analytics and then presents a discussion of challenges and future directions \nfor effectively learning context-aware rules from smartphone data, in order to build \nrule-based automated and intelligent systems.\n\nKeywords: Smartphone data, Machine learning, Data science, Clustering, \nClassification, Association, Rule learning, Personalization, Time-series, User behavior \nmodeling, Predictive analytics, Context-aware computing, Mobile and IoT services, \nIntelligent systems\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nSarker  J Big Data            (2019) 6:95  \nhttps://doi.org/10.1186/s40537‑019‑0258‑4\n\n*Correspondence:   \nmsarker@swin.edu.au \n1 Swinburne University \nof Technology, \nMelbourne VIC-3122, \nAustralia\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0258-4&domain=pdf\n\n\nPage 2 of 25Sarker  J Big Data            (2019) 6:95 \n\n“Tablet Computer” for the last 5 years from 2014 to 2019. Figure 1 represents timestamp \ninformation in terms of particular date in x-axis and corresponding search interests in \nthe range of 0 to 100 in terms of popularity relative to the highest point on the chart in \ny-axis. For instance, a value of 100 (maximum) in y-axis represents the peak popularity \nfor a particular term, while 0 (minimum) means the term was lowest in terms of popu-\nlarity [4].\n\nDue to the advanced features and recent developments in smartphones, these devices \ncan collect raw contextual data about users’ surrounding environment and their corre-\nsponding behavioral activities with their phones in a daily basis [5]. As a result, smart-\nphone data becomes a great source to understand users’ behavioral activity patterns in \ndifferent contexts, and to derive useful information, i.e., context-aware rules, for the pur-\npose of building rule-based intelligent context-aware systems. A context-aware rule has \ntwo parts, which follows “IF-THEN” logical structure to formulate [6]. The antecedent \npart represents users’ surrounding contextual information, e.g., temporal context, spa-\ntial context, social contexts, or others relevant contextual information and the conse-\nquent part represents their corresponding behavioral activities or usage. Let’s consider \nan example of a context-aware mobile notification management system for a smart-\nphone user Alice. A context-aware rule for such system could be “The user typically \ndismisses mobile notifications while at work; however, accepts the notifications in the \nevening from her family members, even though she is in work”. A set of such context-\naware behavioral rules including general and specific exceptions, may vary from user-to-\nuser according to their preferences. In addition to the personalized services mentioned \nabove, the relevant context-aware rules in different surrounding contexts could be appli-\ncable to other broad application areas, like context-aware  software and IoT services, \nintelligent eHealth services, and context-aware smart city services, intelligent cybersecu-\nrity services etc. utilizing the relevant contextual data of that particular domain. Overall, \nthis study is typically for those data science and machine learning researchers, and prac-\ntitioners who particularly want to work on data-driven intelligent context-aware systems \nand services based on machine learning rules.\n\nEffectively learning context-aware rules from smartphone data is challenging because \nof many reasons, ranging from understanding raw data to applications. A number of \nresearch [7–9] has been done on mining context-aware rules from smartphone data for \nvarious purposes. However, to effectively learn such rules for the purpose of building \n\nFig. 1 Users’ interest trends over time, where x-axis and y-axis represent a particular timestamp and \ncorresponding search interests in numeric values in terms of world-wide popularity respectively\n\n\n\nPage 3 of 25Sarker  J Big Data            (2019) 6:95 \n\nintelligent context-aware systems, a deeper analysis in contextual data patterns and \nlearning according to individuals’ usage is needed. Thus, advanced data analysis based \non machine learning techniques, can be used to make effective and efficient decision-\nmaking capabilities in different context-aware test cases for smartphones. Several \nmachine learning and data mining techniques, such as contextual data clustering, fea-\nture optimization and selection, rule-based classification and association analysis, incre-\nmental learning for dynamic updating and management, and corresponding rule-based \nprediction model can be designed to provide smartphone data analytic solutions. The \nreason is that such machine learning techniques can be more accurate, and more precise \nfor analyzing huge amount of contextual data. The aim of these advanced analytic tech-\nniques is to discover information, hidden patterns, and unknown correlations among the \ncontexts and eventually generate context-aware rules. For instance, a detailed analysis \nof time-series data and corresponding data clustering based on similar behavioral pat-\nterns, could lead to capture the diverse behaviors of an individual’s activities, thereby \nenabling more optimal time-based context-aware rules than the traditional approaches \n[10]. Thus, intelligent data-driven decisions using machine learning techniques can \nprofit better decision making capability over the traditional approaches while consider-\ning the multi-dimensional contexts.\n\nBased on our survey and analysis on existing research, little work has been done in \nterms of how machine learning techniques significantly impact on contextual smart-\nphone data and to learn corresponding context-aware rules. To address this short-\ncoming, this article first makes a survey on previous work in the area of contextual \nsmartphone data analytics in several perspectives involved in context-aware rules, such \nas time-series modeling that is also known as a discretization of temporal context, rule \ndiscovery techniques, and incremental learning and rule updation techniques, which has \nbeen highlighted in our earlier work [6]. After that this article presents a brief discussion \non challenges and future directions to overcome these issues. Based on our discussion, \nfinally we suggest a machine learning based context-aware rule learning framework for \nthe purpose of effectively learning context-aware rules from smartphone data, in order \nto build rule-based automated and intelligent systems.\n\nThe contributions of this paper are summarized as follows.\n\n• We first make a brief survey on previous work in the area of smartphone data analyt-\nics in several perspectives related to context-aware rule learning and summarize the \nshortcomings of these research.\n\n• We then present a brief discussion on the challenges and future directions to over-\ncome the issues to learn context-aware rules from smartphone data.\n\n• Finally, we suggest a machine learning based context-aware rule learning framework \nand briefly discuss the role of various layers associated with the framework, for the \npurpose of building rule-based intelligent context-aware systems.\n\nTo the best of our knowledge, this is the first article surveying context-aware rule learn-\ning strategies from smrtphone data. The remainder of the paper is organized as follows. \n“Background: contexts and smartphone data” section presents background information \non contexts and contextual smartphone data. “Context-aware rule learning strategies” \n\n\n\nPage 4 of 25Sarker  J Big Data            (2019) 6:95 \n\nsection  surveys previous work in various perspectives related to context-aware rule \nlearning. “Challenges and future directions” section briefly discusses the challenges and \nfuture directions of research regarding context-aware rule learning from smartphone \ndata. In “Suggested machine learning based framework” section we suggest a machine \nlearning based context-aware rule learning framework and discuss various layers with \ntheir roles while learning rules. Context-aware rule based applications section summa-\nrizes a number of real world applications based on context-aware rules. Finally, “Conclu-\nsion” section concludes this paper.\n\nBackground: contexts and smartphone data\nThis section reviews background information on the main characteristics of contexts \nand contextual smartphone data that address learning context-aware rules for the pur-\npose of building rule-based intelligent systems.\n\nCharacteristics of contexts\n\nThe term context can be used with a variety of different meanings in different purposes. \nThe notion of context has been used in numerous areas, including Pervasive and Ubiq-\nuitous Computing, Human Computer Interaction, Computer-Supported Collaborative \nWork, and Ambient Intelligence [11]. In this section, first we briefly review what is con-\ntext in the area of mobile and context-aware computing. In Ubiquitous and Pervasive \nComputing area, early works on context-awareness referred to context as primarily \nthe location of people and objects [12]. In recent works, context has been extended to \ninclude a broader collection of factors, such as physical and social aspects of an entity, \nas well as the activities of users [11]. Having examined the definitions and categories of \ncontext given by the pervasive and ubiquitous computing community, this section seeks \nto define our view of context within the scope of smartphone data analytics. As the defi-\nnitions of context to pervasive and ubiquitous computing area are also broad, this dis-\ncussion is intended to be illustrative rather than exhaustive.\n\nSeveral studies have attempted to define and represent the context from different \nperspectives. For instance, the user’s location information, the surrounding people and \nobjects around the user, and the changes to those objects are considered as contexts by \nSchilit et al. [12]. Brown et al. [13] also define contexts as user’s locational information, \ntemporal information, the surrounding people around the user, temperature, etc. Simi-\nlarly, the user’s locational information, environmental information, temporal informa-\ntion, user’s identity, are also taken into account as contexts by Ryan et  al. [14]. Other \ndefinitions of context have simply provided synonyms for context such as context as the \nenvironment or social situation. A number of researchers are taken into account the \ncontext as the environmental information of the user. For instance, in [15], the environ-\nmental information that the user’s computer knows about are taken into account as con-\ntext by Brown et al., whereas the social situation of the user is considered as a context \nin Franklin et al. [16]. On the other hand, a number of other researchers consider it to \nbe the environment related to the applications. For instance, Ward et al. [17] consider \nthe state of the surrounding information of the applications as contexts. Hull et al. [18] \ndefine context as the aspects of the current situation of the user and include the entire \n\n\n\nPage 5 of 25Sarker  J Big Data            (2019) 6:95 \n\nenvironment. The settings of applications are also treated as context in Rodden et  al. \n[19].\n\nAccording to Schilit et  al. [20] the important aspects of context are: (i) where you \nare, (ii) whom you are with, and (iii) what resources are nearby. The information of the \nchanging environment is taken into account as context in their definition. In addition to \nthe user environment (e.g., user location, nearby people around the user, and the cur-\nrent social situation of the user), they also include the computing environment and the \nphysical environment. For instance, connectivity, available processors, user input and \ndisplay, network capacity, and costs of computing can be the examples of the computing \nenvironment, while the noise level, temperature, the lighting level, can be the examples \nof the physical environment. Dey et al. [21] present a survey of alternative view of con-\ntext, which are largely imprecise and indirect, typically defining context by synonym or \nexample. Finally, they offer the following definition of context, which is perhaps now the \nmost widely accepted. According to Dey et al. [21] “Context is any information that can \nbe used to characterize the situation of an entity. An entity is person, place or object \nthat is considered relevant to the interaction between a user and an application, includ-\ning the user and the application themselves”. Thus, based on the definition of Dey et al. \n[21], we can define context in the scope of this work as “Context is any information that \ncan be used to characterize users’ day-to-day situations that have an influence on their \nsmartphone usage”. An example of relevant contexts could be temporal context, spatial \ncontext, or social context etc. that might have an influence to make individuals’ diverse \ndecisions on smartphone usage in their daily life activities.\n\nContextual smartphone data\n\nWe live in the age of data [22], where everything that surrounds us is linked to a data \nsource and everything in our lives is captured digitally. Mobile or cellular phones have \nbecome increasingly ubiquitous and powerful to log user diverse activities for under-\nstanding their preferences and phone usage behavior. For instance, smart mobile phones \nhave the ability to log various types of context data related to a user’s phone call activities \nabout when the user makes outgoing calls, or accepts, rejects, and misses the incoming \ncalls [23–26]. In addition to such call related meta data, other dimensions of contex-\ntual information such as user location [27], user’s day-to-day situation [28], the social \nrelationship between the caller an callee identified by the individual’s unique phone \ncontact number [29] are also recorded by the smart mobile phones. Thus, call log data \ncollected by the smart mobile phone can be used as a context source to modeling indi-\nvidual mobile phone user behavior in smart context-aware mobile communication sys-\ntems [30]. In addition to voice communication, short message service (SMS) is known \nas text communication service allows the exchange of short text messages of individual \nmobile phone users, using standardized communications rules or protocols. According \nto the International Telecommunication Union [31], short messages have become a mas-\nsive commercial industry, worth over 81 billion dollars globally. The numerous growth \nin the number of mobile phone users in the world has lead to a dramatic increasing of \nspam messages [32]. The SMS log contains all the message including the spam and non-\nspam text messages [32, 33], which can be used in the task of automatic spam filtering \n[25, 32], or predicting good time or bad time to deliver such messages [33].\n\n\n\nPage 6 of 25Sarker  J Big Data            (2019) 6:95 \n\nWith the rapid development of smartphones, people use these devices for using vari-\nous categories of apps such as Multimedia, Facebook, Gmail, Youtube, Skype, Game [9, \n34]. Thus, smartphone apps log contains these usage with relevant contextual informa-\ntion [8, 9, 35–37]. Such logs can be used for mining the contextual behavioral patterns of \nindividual mobile phone users that is, which app is preferred by a particular user under \na certain context to provide personalized context-aware recommendation. In the real \nworld, a variety of smart mobile applications use notifications in order to inform the \nusers about various kinds of events, news or just to send them reminders or alerts. For \ninstance, the notifications of inviting games on social networks, social or promotional \nemails, or a number of predictive suggestions by various smart phone applications, \ne.g., Twitter, Facebook, LinkedIN, WhatsApp, Viver, Skype, Youtube [7]. The extracted \ncontextual patterns from smartphone notification logs can be used to build intelligent \nmobile notification management systems according to their preferences.\n\nUser navigation in the web in another major activities of individual users. Thus, web \nlog contains the information about user mobile web navigation, web searching, e-mail, \nentertainment, chat, misc, news, TV, netting, travel, sport, banking, and related contex-\ntual information [38–40]. Mining contextual usage patterns from such log data, can be \nused to make accurate context-aware predictions about user navigation and to adapt the \nportal structure according to the needs of users. Similarly, game log contains the infor-\nmation about playing various types such games such as action, adventure, casual, puzzle, \nRPG, strategy, sports etc. of individual mobile phone users, and related contextual infor-\nmation [41]. The extracted contextual patterns from such logs data, can be used to build \npersonalized mobile game recommendation system for individual mobile phone users \naccording to their own preferences.\n\nThe ubiquity of smart mobile phones and their computing capabilities for various real \nlife purposes provide an opportunity of using these devices as a life-logging device, i.e., \npersonal e-memories [42]. In a more technical sense, life-logs sense and store individ-\nual’s contextual information from their surrounding environment through a variety of \nsensors available in their smart mobile phones, which are the core components of life-\nlogs such as user phone calls, SMS headers (no content), App use (e.g., Skype, What-\nsapp, Youtube etc.), physical activities form Google play API, and related contextual \ninformation such as WiFi and Bluetooth devices in user’s proximity, geographical loca-\ntion, temporal information [42]. The extracted contextual patterns or behavioral rules of \nindividual mobile phone users utilizing such life log data, can be used to improve user \nexperience in their daily life. In addition to these personalized log data, smartphones are \nalso capable for collecting and processing IoT data [1]. Based on such smartphone data \nhaving contextual information, in this paper, we briefly review the existing rule learn-\ning strategies and discuss the open challenges and opportunities by highlighting future \ndirections for context-aware rule learning.\n\nContext‑aware rule learning strategies\nIn this section, we review existing strategies related to learning rules based on contex-\ntual information in various perspectives. This includes time-series modeling that cre-\nates behavioral data clusters for generating temporal context based rules, contextual rule \n\n\n\nPage 7 of 25Sarker  J Big Data            (2019) 6:95 \n\ndiscovery by taking into account multi-dimensional contexts, such as temporal, spatial \nor social contexts, and incremental learning to dynamic updating of rules.\n\nModeling time‑series smartphone data\n\nTime is the most important context that impacts on mobile user behavior for making \ndecisions [38]. Individual’s behaviors vary over time in the real world and the mobile \nphones record the exact time of all diverse activities of the users with their mobile \nphones. A time series is a sequence of data points ordered in time [43]. However, to use \nsuch time-series data into behavioral rules, an effective modeling of temporal context \nis needed. Thus, time-series segmentation becomes one of the research focuses in this \nstudy as exact time in mobile phone data is not very informative to mine behavioral rules \nof individual mobile phone users. According to [44], time-based behavior modeling is an \nopen problem. Hence, we summarize the existing time-series segmentation approaches \n\nTable 1 Various types of static time segments used in different applications\n\nTime interval type Number \nof segments\n\nUsed time interval and segment details References\n\nEqual 3 Morning [7:00–12:00], afternoon [13:00–18:00] and \nevening [19:00–24:00]\n\nSong et al. [46]\n\nEqual 3 [0:00–7:59], [8:00–15:59] and [16:00–23:59] Rawassizadeh et al. [47]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nMukherji et al. [48]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nBayir et al. [49]\n\nEqual 4 Morning, afternoon, evening and night Paireekreng et al. [41]\n\nEqual 4 Morning [6:00–11:59], day [12:00–17:59], evening \n[18:00–23:59], overnight [0:00–5:59]\n\nJayarajah et al. [50]\n\nEqual 4 Night [0:00–6:00 a.m.], morning [6:00 a.m.–12:00 \np.m.], afternoon [12:00–6:00 p.m.], and evening \n[6:00 p.m.–0:00 a.m.]\n\nDo et al. [51]\n\nUnequal 3 Morning (beginning at 6:00 a.m. and ending at \nnoon), afternoon (ending at 6:00 p.m.), night (all \nremaining hours)\n\nXu et al. [52]\n\nUnequal 4 Morning [6:00–12:00], afternoon [12:00–16:00], \nevening [16:00–20:00] and night [20:00–24:00 \nand 0:00–6:00]\n\nMehrotra et al. [7]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00] and so on\n\nZhu et al. [9]\n\nUnequal 5 Morning, forenoon, afternoon, evening, and night Oulasvirta et al. [53]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00], evening [18:00–21:00], and \nnight [21:00–Next day 7:00]\n\nYu et al. [54]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nNaboulsi et al. [55]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nDashdorj et al. [56]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nShin et al. [57]\n\nUnequal 8 S1[0:00–7:00 a.m.], S2[7:00–9:00 a.m.], S3[9:00–\n11:00 a.m.], S4[11:00 a.m.–2:00 p.m.], S5[2:00–\n5:00 p.m.], S6[5:00–7:00 p.m.], S7[7:00–9:00 p.m.] \nand S8[9:00 p.m.–12:00 a.m.]\n\nFarrahi et al. [58]\n\n\n\nPage 8 of 25Sarker  J Big Data            (2019) 6:95 \n\ninto two broad categories; (i) static segmentation, and (ii) dynamic segmentation, that \nare used in various mobile applications.\n\nStatic segmentation\n\nA static segmentation is easy to understand and can be useful to analyze population \nbehavior comparing across the mobile phone users. In order to generate segments, \nrecently, most of the researchers (shown in Table 1) take into account only the temporal \ncoverage (24-h-a-day) and statically segment time into arbitrary categories (e.g., morn-\ning) or periods (e.g., 1 h). Such static segmentation of time mainly focuses on time inter-\nvals. According to [45], there are mainly two types of time intervals: one is equal and \nanother one is unequal. For instance, four different time segments, i.e., morning [6:00–\n12:00], afternoon [12:00–18:00], evening [18:00–24:00] and night [0:00–6:00] can be an \nexample of equal interval based segmentation because of their same interval length. On \nthe other hand, another four time slots such as morning [6:00–12:00], afternoon [12:00–\n16:00], evening [16:00–20:00] and night [20:00–24:00 and 0:00–6:00] can be an example \nof unequal interval based segmentation. For this example, different lengths of time inter-\nval are used to do the segmentation. In Table 1, we have summarized a number of works \nthat use static segmentation considering either equal or unequal time interval in various \npurposes.\n\nAlthough, various time intervals and corresponding segmentation summarized in \nTable 1 are used in different purposes, these approaches take into account a fixed num-\nber of segments for all users. However, while performing such segmentation users’ behav-\nioral evidence that differs from user-to-user over time in the real world, is not taken into \naccount. Thus, these static generation of segments may not suitable for producing high \nconfidence temporal rules for individual smartphone users. For instance, N1 number \nof segments might give meaningful results for one case, while N2 number of segments \ncould give better results for another case, where N1  = N2 . Therefore, a dynamic segmen-\ntation of time rather than statically generation could be able to reflect individuals’ behav-\nioral evidence over time and can play a role to produce high confidence rules according \nto their usage records.\n\nDynamic segmentation\n\nAs discussed above, a segmentation technique that generates variable number of seg-\nments would be more meaningful to model users’ behavior. Thus, dynamic segmenta-\ntion technique rather than static segmentation can be used in order to achieve the goal. \nIn a dynamic segmentation, the number of segments are not fixed and predefined; may \nchange depending on their behavioral characteristics, patterns or preferences. Several \ndynamic segmentation techniques in terms of generating variable number of segments \nexist for modeling users’ behavioral activities in temporal contexts. A number of authors \nsimply take into account a single parameter, e.g., interval length or base period, to gener-\nate the segments. The number of time segments varies according to this period. If Tmax \nrepresents the whole time period of 24-h-a-day and BP is a base period, then the num-\nber of segments will be Tmax/BP [10]. If the base period increases, the number of time \nsegments decreases and vice-versa. For instance, if the base period is 5 min, then the \nnumber of segments will be the division result of 24-h-a-day and 5. In this example, a \n\n\n\nPage 9 of 25Sarker  J Big Data            (2019) 6:95 \n\nbase period, e.g., 5 min, is assumed as the finest granularity to distinguish day-to-day \nactivities of an individual. If the base period incremented to 15 min, then the number \nof segments decreases, where 15 min can be assumed as the finest granularity. Thus the \nnumber of segments varies based on the base time period. Similarly, individuals’ calen-\ndar schedules and corresponding time boundaries can also be used to determine var-\niable length of time segments, in order to model users’ behavior in temporal context, \nwhich may vary according to users’ preferences [59]. For instance, one user may have a \nparticular event between 1 and 2 p.m., while another may have in another time bound-\nary between 1:30 and 2:30 p.m.. Thus, the time segmentation varies according to their \ndaily life activities scheduled in their personal calendars. Similarly, multiple thresholds, \nsliding window, data shape based approaches are used in several applications, shown \nin Table 2. In addition to these approaches, a number of authors use machine learning \ntechniques such as clustering, genetic algorithm etc. In Table  2, we have summarized \na number of works that use such type of dynamic segmentation techniques in various \npurposes.\n\nClustering highlighted in Table  2 is one of the important machine learning tech-\nniques in forming large time segments where certain user behavior patterns are taken \ninto account. Usually, clustering algorithms are designed with certain assumptions and \nfavor certain type of problems. In this sense, it is not accurate to say ‘best’ in the con-\ntext of clustering algorithms; it depends on specific application [75]. Among the cluster-\ning algorithms the K-means algorithm is the best-known squared error-based clustering \nalgorithm [76]. However, this algorithm needs to specify the initial partitions and fixed \nnumber of clusters K. The convergence centroids also vary with different initial points. \nSometimes this algorithm is influenced by outliers because of mean value calculation. \n\nTable 2 Various types of dynamic time segments used in different applications\n\nBase technique Description References\n\nSingle parameter A predefined value of time interval, e.g., 15 min \nis used to generate segments\n\nOzer et al. [60]\n\nA different value of time interval, e.g., 30 min is \nused for segmentation\n\nDo et al. [61], Farrahi et al. [62]\n\nA relatively large value of the parameter, e.g., \n2-h is used to generate time segments\n\nKaratzoglou et al. [63]\n\nAnother large value of time interval, e.g., 3-h is \nused for segmentation to make the number \nof segments small\n\nPhithakkitnukoon et al. [64]\n\nCalendar Various calendar schedules and corresponding \ntime boundaries are used to model users’ \nbehavior in temporal context\n\nKhail et al. [65], Dekel et al. [66], Zulkernain \net al. [67], Seo et al. [68], Sarker et al. [28, \n59]\n\nMulti-thresholds To identify the lower and upper boundary \nof a particular segment for the purpose of \nsegmenting time-series log data\n\nHalvey et al. [38]\n\nData shape A data shape based time-series data analysis Zhang et al. [45], Shokoohi et al. [69]\n\nSliding window A sliding window is used to analyze time-series \ndata\n\nHartono et al. [70], Keogh et al. [71]\n\nClustering A predefined number of clusters is used to \ndiscover rules from time-series data\n\nDas et al. [72]\n\nGenetic algorithm A genetic algorithm is used to analyze time-\nseries data\n\nLu et al. [73], Kandasamy et al. [74]\n\n\n\nPage 10 of 25Sarker  J Big Data            (2019) 6:95 \n\nMore importantly, the characteristic of this algorithm might not be directly applicable \nfor the purpose of learning  context-aware rules. The reason is that users’ behave dif-\nferently in different contexts, which also may vary from user-to-user in the real world. \nThus, it’s difficult to assume a number of clusters K to capture their diverse behaviors \neffectively. Another similar K-medoids method [77] is more robust than K-means algo-\nrithm in the presence of outliers because a medoid is less influenced by outliers than a \nmean. Though it minimizes the outlier problem but the other characteristic mismatches \nexist between K-means and the problem of time-series modeling.\n\nAs the size and number of time segments depend on the user’s behavior and it differs \nfrom user-to-user, a bottom-up hierarchical data processing can help to make behavioral \nclusters. Existing hierarchical algorithms are mainly classified as agglomerative methods \nand device methods. However, the device clustering method is not commonly used in \npractice [75]. The simplest and most popular agglomerative clustering is single linkage \n[78] and complete linkage [79]. Another method, nearest neighbor [75], is also similar to \nthe single linkage agglomerative clustering algorithm. All these hierarchical algorithms \nuse a proximity matrix which is generated by computing the distance between a new \ncluster and other clusters. Then according to the matrix value these algorithms succes-\nsively merge the clusters until the desired cluster structure is obtained. However, it is \nnot possible to predict the level at which the merging is best according to a proximity \nmatrix because of the variations in users’ behavior. Thus applying such clustering tech-\nniques could generate the segments according to users’ behavioral patterns available in \ntime-series. Similarly, genetic algorithm based approaches shown in Table  2 also pro-\nduce dynamic segments.\n\nIn a summary, we can conclude that time-series modeling in terms of both static seg-\nmentation and dynamic segmentation approaches discussed above, are able to generate \nvarious time segments that can be used in different purposes. However, the above time-\nseries modeling approaches do not necessarily map to the patterns of individuals’ usage \naccording to their preferences, which is based on users’ diverse behaviors over time-of-\nthe-week and may vary from user to user. A machine learning based behavior-oriented \ndynamic time-series modeling technique by taking into account such patterns, could be \nsignificant in order to effectively use temporal context as the basis for discovering rules \ncapturing smartphone usage behavior.\n\nRule discovery\n\nAnother major issue focus in this study is discovering useful behavioral rules of individ-\nual mobile phone users based on multi-dimensional contexts, such as temporal, spatial, \nor social contexts, utilizing their smartphone data. In the area of machine learning both \nassociation rule learning [80] and classification rule learning [81] are the most common \ntechniques to discover such type of rules of individual mobile phone users. In the follow-\ning, we give an brief overview of both association and classification techniques for the \npurpose of discovering rules based on multi-dimensional contexts.\n\n\n\nPage 11 of 25Sarker  J Big Data            (2019) 6:95 \n\nAssociation rules\n\nAssociation rule learning algorithm discovers association rules that satisfy the prede-\nfined minimum support and confidence constraints from a given dataset [80]. Many \nassociation rule learning algorithms have been proposed in the data mining literature, \nsuch as logic based [82], frequent pattern based [80, 83, 84], tree-based [85] etc. Asso-\nciation rule learning technique is well defined in terms of rule’s performance, e.g., accu-\nracy, and flexibility as it has the own parameter support and confidence [86]. A number \nof researchers [7–9] have used association rule learning technique (e.g., Apriori) [80] \nto mine rules capturing mobile phone users’ behavior. However, the existing  associa-\ntion rule learning techniques might not be suitable for discovering users’ behavioral \nrules because of several reasons. In the following, we summarize the drawbacks of asso-\nciation rules for discovering the behavioral rules of individual mobile phone users by \ntaking into account multi-dimensional contexts.\n\nLacking in understanding the impact of contexts Different contexts in mobile phone \ndata, such as temporal, spatial or social context, may have different impact or influence \non the behavioral rules of individual mobile phone users. For instance, incoming phone \ncalls from a significant person, e.g., mother, is always answered by an individual, even \nthough she is in a meeting because of her family priority. In this case, the importance \nof social relationship between individuals ( social relationship → mother ) in making \nbehavioral decision, is higher than other relevant contexts such as time period, weekday \nor holiday, location, accompany with etc. However, the typical association rule learn-\ning technique implicitly assumes all the contexts in the datasets have the similar nature, \nand/or impact while discovering rules based on multi-dimensional contexts.\n\nRedundancy Association rule learning technique, e.g., Apriori, discovers all the con-\ntextual associations in a given dataset, if it satisfies the user preference, specified as \nminimum support value and minimum confidence value. As a result, association rule \nlearning technique produces a huge number of redundant rules as it does not take into \naccount the usefulness of a particular context or corresponding patterns while produc-\ning the associations. For instance, it produces up to 83% redundant rules for a given \ndataset that makes the rule-set unnecessarily large [87]. Therefore, it is very difficult to \ndetermine the most interesting ones among the huge amount of rules generated. As a \nresult, it makes the rule-based decision making process ineffective and more complex, \nwhich is not effective to build a context-aware intelligent system [88].\n\nComputational complexity and high training time In order to produce rules, associ-\nation rule learning technique takes huge amount of training time. For instance, in an \nexperimental study in mobile phone domain, the authors observe a high running time \nspanning several hours when the association rule learning algorithm is used to discover \nuser behavioral rules [8]. The main reason for taking high training time is that typical \nassociation techniques compute all the possible associations among contexts and are \nunable to filter the interesting rules that can be used to make effective decisions. As a \nresult the unnecessary generation of patterns increases the computational complexity \nand training time.\n\nIn a summary, by taking into account the impact of contexts, redundancy problem \nwhile generating rules, and computational complexity, typical association rule learning \n\n\n\nPage 12 of 25Sarker  J Big Data            (2019) 6:95 \n\ntechniques may not suitable to produce users’ behavioral rules in multi-dimensional \ncontexts, for the purpose of building intelligent context-aware systems.\n\nClassification rules\n\nClassification is another technique to discover user behavioral rules from the datasets. \nSeveral classification algorithms exist with the ability of rule generation like ZeroR [89], \nOneR [90], RIDOR [89], RIPPER [91], PART [92], DTNB [93], Decision Trees [81, 94] \netc. Among these techniques, decision tree is one of the most popular rule-based clas-\nsification algorithms as it has several advantages, such as easier to interpret; the ability \nto handle high dimensional data; simplicity and speed; good accuracy; and the ability to \ngenerate human understandable classification rules [95, 96]. In particular, a number of \nauthors [67, 97–100] have used decision tree classification technique to discover rules \ncapturing mobile phone users’ behavior for various purposes. However, the exisitng rule-\nbased classification techniques might not be suitable to model users’ behavior because of \nseveral reasons. In the following, we summarize the drawbacks of rule-based classifica-\ntion techniques for discovering the behavioral rules of individual mobile phone users in \nmulti-dimensional contexts.\n\nLow reliability In general, reliability refers the quality of being trustworthy or of per-\nforming consistently well. A pattern or rule is called reliable, if the relationship described \nby the pattern occurs in a high percentage of applicable cases. According to Geng et al. \n[101], a classification rule will be reliable, if it gives high prediction accuracy, and an \nassociation rule will be reliable, if it has high confidence that is associated to the accu-\nracy. However, the classification rules discovered by the typical rule-based classifica-\ntion techniques, e.g., decision trees, mostly have low reliability in many cases [7, 102]. \nAccording to Freitas et al. [86], a classification rule may not ensure a high accuracy in \npredictions. The reason is that it may has over-fitting problem and inductive bias, which \ndecrease the prediction accuracy of a machine learning based model.\n\nLacking in flexibility Traditional rule-based classification techniques, e.g., decision \ntrees, have no flexibility to set users’ preferences and consequently it makes rigid decision \nfor a particular test case [81]. However, rigid decision in modeling user behavior might \nnot be meaningful by considering real-world cases. The reason is that individuals’ pref-\nerences are not static in the real word; may vary from user-to-user [103]. For instance, \none individual may want the phone call agent to decline the incoming calls where she \ndid not answer the calls more than, say, 80% of the time in the past. For another person, \nthis preference could be 95% of the time according to her preference. Thus considering \nflexibility in users’ preferences while modeling their behavior could be another issue for \nmaking meaningful decisions in various context-aware test cases. \n\nLacking in generalization Typically, generality measures the comprehensiveness of a \npattern or rule, that is, the fraction of all the relevant records in the dataset that matches \nthe pattern. According to Geng et  al. [101], if a pattern characterizes more informa-\ntion in the relevant dataset, it tends to be more useful and interesting. Traditional clas-\nsification techniques consider data-driven generalization while producing classification \nrules. Besides this, users’ behavior-oriented generalization might be interested for learn-\ning context-aware rules. For instance, users’ behavior might be similar for a collection \nof contexts and have exceptions only in few cases [6]. Thus, users’ behavior oriented \n\n\n\nPage 13 of 25Sarker  J Big Data            (2019) 6:95 \n\ngeneralization could give more precise results for modeling their usage behavior. The \ngeneralization not only simplifies the resultant machine learning based model but also \nminimizes the over-fitting problem and improves the prediction accuracy.\n\nIn a summary, by taking into account the reliability, flexibility, and generalization dis-\ncussed above, typical classification rule learning techniques may not be suitable to pro-\nduce users’ behavioral rules in multi-dimensional contexts, for the purpose of building \nintelligent context-aware systems.\n\nIncremental learning and updating\n\nIn the area of data mining, a number of updating techniques, known as incremental rule \nmining, have been proposed for discovering rules in a dynamic database. These tech-\nniques use existing discovered rules and the incremental part of the dataset to get a com-\nplete updated set of rules. For instance, FUP algorithm proposed by Cheung et al. [104] \nis the first incremental updating technique for maintaining association rules when new \ndata are inserted to database. The FUP algorithm is based on Apriori [80] algorithm and \nis used to discover the new frequent itemsets in a dynamic database. In [105], Cheung \net al. propose a new algorithm FUP2 which is an extension of FUP algorithm. Another \nincremental association rule mining algorithm is proposed by Xu et al. [106]. They pro-\npose an IFP-tree technique which is an extension of FP-tree [85]. Thomas et  al. [107] \npropose an algorithm based on the concept of negative border which maintains both \nfrequent itemsets and border itemsets.\n\nA few number of algorithms [108, 109] are proposed based on three-way decision that \nis an extension of the commonly used binary-decision model with an added third option. \nA theory of three-way decision is constructed based on the notions of acceptance, rejec-\ntion and no commitment proposed by Yao et al. [110]. In [111], Amornchewin et al. pro-\npose a probability-based incremental association rule discovery algorithm. Thusaranon \net  al. [112] propose another probability-based incremental association rule discovery \nalgorithm that is an extension work of the algorithm introduced by Amornchewin and \nKreesuradej [111].\n\nThe above incremental mining techniques mainly take into account the faster process-\ning, e.g., efficiency, of overall mining process. While processing, these techniques reduce \nthe scanning on the given datasets by mining the incremental part separately, instead of \nprocessing the merged dataset that includes the initial dataset and the incremental part. \nThus, the overall mining process of such traditional updating techniques reflects on the \nprocessing time to discover a complete set of updated rules. However, to model users’ \nbehavior the freshness of rules, e.g., rules based on recent patterns are significant, which \nhas not been taken into account in these techniques. The reason is that users’ behav-\nior are not static in the real world; may change over time. Thus, the updation in terms \nof freshness in users’ behavior while producing rules are needed to effectively modeling \nsmartphone users’ behavior in relevant multi-dimensional contexts.\n\nIn order to produce rules according to the current behavior of an individual, a number \nof researchers use the behavioral patterns of recent mobile phone log data to predict \nthe future behavior than the patterns derived from the entire historical logs. However, \nthey use a static period of recent historical data that might not meaningful for discover-\ning users’ recent behavioral rules. For instance, Lee et al. [113] have studied the mobile \n\n\n\nPage 14 of 25Sarker  J Big Data            (2019) 6:95 \n\nphone users’ calling patterns and design a call recommendation algorithm for an adap-\ntive speed-call list using a recent call list data. In their approach, they extract call logs \nfor previous three months to achieve their goal. In order to predict the outgoing calls, \nBarzaiq et al. [114] propose an approach that analyzes mobile phone historical data from \na period of two years and observe relatively additional computational load which seems \nto be unnecessary. Phithakkitnukoon et  al. [115], conduct their study on reality min-\ning datasets that were collected over the period of nine months and observe that only \na recent portion of communication history is more significant. In another work, Phith-\nakkitnukoon et al. [116] present a model for predicting phone calls for the next twenty \nfour hours based on the users’ past communication history. In their approach, they \nhave shown that the recent trend of the user’s calling pattern is more significant than \nthe order one and has higher correlation to the future pattern than the pattern derived \nfrom the entire historical data. As such, the latest sixty days call records in the call logs \nare assumed to be the future observed call activities in order to get better prediction \naccuracy [116]. However, such static period of time consideration may not be suitable to \nreflect one’ current behavior, as users’ behaviors are not consistent in the real world; may \nvary from user-to-user over time.\n\nBesides these approaches, a number of authors [117, 118] deal with the problem of \nmanaging personal information, such as individual’s contact lists in their mobile phone, \nmore specifically, the task of searching the desirable contact number when making an \noutgoing call. According to Bergman et al. [117], a number of contacts in mobile phones \nare never actually used albeit the contact lists become increasingly bigger. Their experi-\nmental results show that 47% of the contacts of the users had not been used for over \nsix months or had never been used at all. To predict future behavior, Stefanis et al. [118], \nhave used window based model for managing and searching of personal information \non mobile phones. In their experiment, they have shown that the training window for \npredicting individual’s mobile phone usages behavior should be long enough to provide \nsufficient data. However, at the same time, a training window of more than two weeks \nwould likely fail to capture the dynamic changes in the behavioral patterns for making \nphone calls. In Addition, a training window of less than seven days would fail to capture \nthe behavioral changes for all the days-of-the-week including a change of social circum-\nstances in the weekends.\n\nIn a summary, by taking into account the freshness in rules reflecting users’ current \nbehavior and their dynamic updation, typical updating techniques discussed above may \nnot be suitable to produce a complete set of users’ behavioral rules in multi-dimensional \ncontexts, for the purpose of building intelligent context-aware systems, in order to pro-\nvide relevant services to the end smartphone users.\n\nChallenges and future directions\nWith the rapid development of smartphones, IoT, data science and machine learning, \nand context-aware computing, the most fundamental challenge is to explore contex-\ntual data collected from relevant sources and to extract context-aware rules for future \nactions. We highlight and analyze the main challenges in extracting rules, machine \nlearning techniques, and context-aware system areas, involved in context-aware rule \nlearning. We also discuss about the future directions to overcome such issues. Thus, this \n\n\n\nPage 15 of 25Sarker  J Big Data            (2019) 6:95 \n\nsection examines the impact of learning context-aware rules on several perspectives dis-\ncussed in this paper, in the broad area of smartphone data analytics. In the following, the \nchallenges and corresponding future directions are discussed briefly.\n\nIn the area of context aware computing, a number of approaches exist in order to \nhandle the continuous contextual features like time-series and to develop time-based \ncontext-aware systems. They are mostly designed by taking into account several categor-\nical time periods with a particular interval either equal or unequal, and corresponding \ntemporal rule based system. Although, a static modeling of temporal context is easy to \nunderstand and can be useful to analyze population behavior comparing across users, \na machine learning based data-driven solution could be an effective way. The reason is \nthat we are now in the age of data science and have available real world contextual data-\nsets in time order due to the rapid growing of IoT and smartphones. Thus, time-series \nmodeling becomes an open problem for building a context-aware system. Although, a \nfew number of learning techniques are employed to create data-driven temporal seg-\nments, they can be improved with advanced data analysis like observing variations in \ntemporal patterns, relation with individuals and population behavior, data sparseness in \ntime-series, synchronizing temporal context with multiple data sources etc. Improved \nmachine learning techniques or hybrid methods could give better results for modeling \nsuch continuous contextual data. For instance, a dynamic behavior-oriented aggregation \nalgorithm [10], could produce better time-series segmentation results for the purpose of \nmodeling time-based user behavior. New machine learning solutions by considering the \nabove mentioned perspectives can be designed and developed to process and analyze \nreal-world time-series data, in order to build an intelligent time-based context-aware \nsystem.\n\nIn addition to temporal context, additional dimensions of contexts might have the \nimpact on context-aware system. Although, association analysis and rule-based classi-\nfication analysis are the well known approaches in machine learning to discover rules, \nstill there are some issues to learn context-aware rules using these techniques. For \ninstance, an association learning technique produces a large amount of redundant rules \nthat makes the context-aware system complex and ineffective. On the otherhand, clas-\nsification techniques produce rules for rigid decision making that becomes non-reliable \nin many context-aware cases. Thus, effectively learning rules based on multi-dimen-\nsional contexts becomes another challenge. Although, both the classification and asso-\nciation analysis are well established methods in the area of machine learning, improved \nmachine learning techniques or hybrid methods could give better results for learning \neffective rules based on multi-dimensional contexts. For instance, the problem of redun-\ndancy while generating the association rules can be minimized by taking into account \nthe precedence of contexts [119]. Thus, advanced functionality and their combinations \nin machine learning, like the precedence of contexts, optimum contextual feature selec-\ntion, users’ preference-oriented discovery, generalization, abnormality or  exceptional \ndiscovery etc. could produce more effective rules. New machine learning based solu-\ntions or potential hybrid methods by considering these functionalities can be designed \nand developed to process and analyze real-world contextual data, in order to build a \nrule-based intelligent context-aware system that behaves accordingly.\n\n\n\nPage 16 of 25Sarker  J Big Data            (2019) 6:95 \n\nIn recent days, rule-based context-aware systems become popular due to the rapid \ngrowing of IoT and smartphones. Some of them are static rule based system particularly \ndesigned and developed according to the current needs. A number of such rule based \ncontext-aware systems are designed by taking into account rules discovered from data \nusing association learning or classification learning techniques. Although, these rule-\nbased systems are capable to provide the relevant services, still there is a lack of system \neffectiveness in terms of prediction accuracy in a human-centric system. In that case, \na machine learning based data-driven solution by taking into account incremental data \nand corresponding learning could be an effective way. The reason is that human behavior \nchanges over time and the most recent pattern is likely to be more significant than older \nones, which can be found from incremental data. Thus, recent patterns based modeling \nbecomes another challenge for building a context-aware system. Although, a number \nof updating techniques are employed in the area of incremental data mining, they can \nbe improved by taking into account the freshness in behavioral analytics for a particu-\nlar context. For instance, a very recent work RecencyMiner [120], could produce bet-\nter prediction results by taking into account recency-based updation for the purpose of \nmodeling user behavior. Thus, new machine learning technique or hybrid learning based \nsolutions by considering advanced functionalities like analyzing dynamic log, behav-\nioral patterns changing, context-aware incremental learning, freshness in rules, can be \ndesigned and developed to build a human-centric intelligent context-aware system that \ntakes into account their recent activities.\n\nThe most important work for intelligent context-aware system is to develop an effec-\ntive framework that supports for learning context-aware rules. Thus, in such a frame-\nwork, we need to consider advanced data analysis based on contexts using machine \nlearning techniques, so that the rule learning framework is capble to resolve these issues. \nThus, a well designed context-aware rule learning framework for contextual smart-\nphone data and the experimental evaluation is a very important direction and a big \nchallenge as well. In a summary, this paper has uncovered several future directions in \nthe field of smartphone data analytics and context-aware rule learning. First, additional \nstudy must be performed on the characteristics of smartphone data in terms of asso-\nciated and relevant contexts, as the context-aware rules depend on surrounding differ-\nent contexts. Second, the scalability and efficacy of existing analytics techniques being \napplied to smartphone data must be empirically examined. Third, new techniques and \nalgorithms or potential hybrid methods are needed to be designed while learning con-\ntext-aware rules, particularly, in terms of time-series modeling, effective rule discovery \nbased on multi-dimensional contexts, and recency-based incremental learning for intel-\nligent decision making utilizing enormous amounts of smartphone data. Fourth, a range \nof empirical evaluation is necessary to measure the effectiveness and efficiency of these \nmachine learning techniques while comparing with existing techniques. Fifth, more \nwork is necessary on how to efficiently model context-aware rules in relevant application \nareas for the purpose of building intelligent context-aware applications.\n\n\n\nPage 17 of 25Sarker  J Big Data            (2019) 6:95 \n\nSuggested machine learning based framework\nAccording to the survey of contextual smartphone data and corresponding rule learn-\ning strategies, in this section, we suggest a context-aware rule learning framework based \non machine learning techniques. Figure 2 shows an overview of the suggested context-\naware rule learning framework highlighting various components starting from the bot-\ntom raw contextual data to real world applications and services. The framework typically \nconsists of four processing layers such as contextual data acquisition layer, context dis-\ncretization layer, rule discovery layer, and finally dynamic updating and management \nlayer, shown in Fig. 2. In the following, we briefly discuss about these layers and their \nroles in learning context-aware rules from smartphone data. These are:\n\nContextual data acquisition This represents the first layer of our context-aware rule \nlearning framework as collecting relevant data is the first step to build a data-driven sys-\ntem. Thus, this layer is responsible to collect individual’s smartphone data that includes \ntheir daily life activities with their phones and corresponding associated contextual \ninformation such as temporal context, spatial context, social context or others relevant \nto the particular usage. Such contextual data can be collected from various sources like \nsmartphone logs, sensors or external sources relevant to the application. Smartphone \ndata collected from these sources usually contains raw contexts that characterize indi-\nviduals’ daily life behavioral activities with their phones, and need to process effectively \nto use as the basis for learning context-aware rules.\n\nFig. 2 An overview of the suggested machine learning based context-aware rule learning framework\n\n\n\nPage 18 of 25Sarker  J Big Data            (2019) 6:95 \n\nContext discretization Machine learning based context discretization represents the \nsecond layer in our context-aware rule learning framework. Once we have available con-\ntextual raw data collected from the data acquisition layer, discretization of contexts is \nneeded to understand the actual meaning of data, which is also known as contextual data \nclustering, highlighted in Fig. 2. In other words, contextual data with similar character-\nistics are grouped in one cluster and dissimilar characteristics are grouped in another \ncluster. For instance, real-world smartphone data contains continuous raw contextual \ninformation like time-series data that represents individual’s diverse activities in differ-\nent data points in time order. Such particular data points separately may not represent \na meaningful behavior of users. A data-driven time-series segmentation using machine \nlearning techniques could give an effective discretization results according to the data \npatterns available in the source. Thus, the main purpose of this layer is to create contex-\ntual data clusters, e.g., segments or contextual groups according to similar data charac-\nteristics. The processed data in this layer helps to find the hidden patterns that are used \nas the basis of learning context-aware rules.\n\nRule discovery Machine learning based contextual rule discovery represents the third \nlayer in our context-aware rule learning framework, shown in Fig. 2. As different con-\ntexts might have different impacts on individuals’ usage behavior in the real world, the \nprecedence analysis of contexts can play a role to discover a set of effective rules, high-\nlighted in Fig. 2. Based on the precedence of contexts, this layer is responsible to gen-\nerate a set of users’ behavioral rules by taking into account relevant multi-dimensional \ncontexts such as temporal context, spatial context, social context or others relevant. The \ngenerated behavioral rules are effective and efficient in terms of reliability that repre-\nsents higher decision making accuracy, conciseness by taking into account the generali-\nzation and non-redundancy, context importance by taking into account the precedence \nof contexts, and lower training time by considering the computing resources in individu-\nals’ devices. Thus, this layer is responsible to generate a set of contextual rules based on \nrelevant multi-dimensional contexts by taking into account these aspects. After discov-\nering rules, this layer is also responsible to rank these rules according to their relevancy \nin terms of contexts and rule’s strength.\n\nDynamic updating and management layer Machine learning based dynamic updat-\ning and management of the discovered rules represents the final layer in our con-\ntext-aware rule learning framework, shown in Fig. 2. As individuals’ usage behavior \nare not static in the real world, may change over time, the recency analysis and min-\ning, and corresponding rule updation can play a role to dynamically update the dis-\ncovered rules over time, highlighted in Fig. 2. Based on the recent behavioral patters \nof individuals’ behavior, this layer outputs a set of users’ behavioral rules by taking \ninto account the relevant contexts. The main benefit of this layer is that it takes into \naccount the most recent pattern that represents the freshness in individuals’ behav-\nior in a particular context, which is likely to be more significant than older ones for \npredicting their future usage. Thus, this layer is one of the significant layers that is \nresponsible to identify the behavioral changing patterns over time, and to update \nand manage the rules dynamically according to their changes in behavioral activities.\n\nOverall, our suggested machine learning based framework is responsible to extract \na set of effective behavioral rules of individual mobile phone users based on relevant \n\n\n\nPage 19 of 25Sarker  J Big Data            (2019) 6:95 \n\nmulti-dimensional contexts utilizing their smartphone data. The extracted context-\naware rules can be used to build various rule-based intelligent systems, in order to \nnot only provide them the target personalized services that may vary from user to \nuser but also the population services in the relevant application areas.\n\nContext‑aware rule based applications\nA context-aware rule based smartphone application represents knowledge in terms of \na set of IF-THEN rules, (i.e., if contexts then user behavioral activities or preferences) \nthat tells what to do or what to conclude in different situations [121] and can act as \na software agent. According to [98], software agent is a new paradigm for developing \nsoftware applications in which an agent is capable of performing autonomous actions \nin a certain environment to achieve it’s goal. The target applications of this research \nare those context-aware personalized applications that have been studied widely in \nthe past few years. For instance, intelligent mobile interruptions management sys-\ntem in one of them. The most popular IoT device, smartphones, are considered to be \n‘always on, always connected’ device and they are always with their users; however \nthe users are not always able to response with the incoming communications because \nof their various day-to-day situations [122]. For this reason, sometimes people are \noften interrupted by incoming phone calls in a working environment [123]. Accord-\ning to the Basex BusinessEdge report [124], the mobile interruptions consume 28% \nof the knowledge worker’s day. It leads to a loss of $700 billion according to Bureau \nof Labor Statistics [125]. In order to manage such interruptions, a number of authors \n[24, 65–67, 126] have studied on static rule based systems. However, the machine \nlearning based context-aware rules can be used to make such system automated and \nintelligent.\n\nSmartphone apps management could be another useful applications for individual \nusers. According to the statistics in Google search, in March 2017, there were 2.8 mil-\nlion apps available at Google Play Store, and 2.2 million apps in the Apple’s App Store. \nThus, its very important to manage such kind of huge amount of available applications. \nMachine learning based context-aware rules can be used to manage these apps accord-\ning to individual’s preferences. Besides apps management, several notifications from dif-\nferent apps are potentially annoying to the users and causes disruptions [7, 127, 128]. \nThe reason is that the users might get irritated for such uninterested phone notifications \n[129, 130]. Thus, machine learning based context-aware rules can also be applicable to \nmanage such notifications intelligently.\n\nSmartphone recommendation system is one of the most important needs for the \nusers. According to [131], the most important feature of a recommender system is its \nability to “guess” a user’s preferences and interests according to their past usage. In gen-\neral, the traditional recommender systems mainly focus on recommending the most \nrelevant items to users among a huge number of items without considering contextual \nimpact [57, 132]. However, the contextual information is needed to recommend accord-\ning to users’ needs [133–135]. For instance, a travel recommender system in the sum-\nmer can be well different from the winter for a particular user, which depends on the \ntemporal context. Similarly another context, e.g., location information, might have the \ninfluence to make different recommendations for the users [136, 137]. Such contextual \n\n\n\nPage 20 of 25Sarker  J Big Data            (2019) 6:95 \n\nrecommendation is important for tourists who travel outside their usual environment \n[138]. As traditional information centers for tourists are not accessible any time any-\nwhere [139], a context-aware web service based tourism information system is needed \n[140]. Thus, machine learning based context-aware rules can be used to make such rec-\nommendation system more intelligent.\n\nIn general, predictive modeling based applications are most important in the area \nof machine learning and smartphone data analytics [141]. Thus, the machine learning \nbased context-aware rules could be more effective to predict user preferences, such as \npredicting calls [116, 118, 142, 143], predicting apps usage [35, 37, 144, 145], predicting \nsmartphone notification [129, 130] etc. The context-aware rules can also play a role to \nbuild a self smartphone configuration management system that includes device volume \nsettings, WiFi turn on or off, GPS turn on or off etc. that reduce battery consumption. \nOverall, the machine learning based context-aware rules extracted from smartphone \ndata can help application developers to build the target intelligent system. In addition \nto the personalized services discussed above, such context-aware rules in different sur-\nrounding contexts could be applicable to other broad application areas, like IoT services, \neHealth services, transportation services, city governance, industry, e-commerce, con-\ntext-aware  cybersecurity intelligence,  and smart city services according to  the  associ-\nated contexts for the purpose of providing intelligent services in relevant context-aware \napplications.\n\nConclusion\nThis paper has discussed how multi-dimensional contexts can impact smartphone data, \nboth in terms of context-aware rule learning and the dataset itself. Our aim was to dis-\ncuss the state of the art with respect to smartphone data analytics and corresponding \nrule learning techniques. We also discussed how multi-dimensional contexts such as \ntemporal, spatial or social contexts can impact such techniques, and examine the chal-\nlenges that remain. For each common technique, we have summarized relevant research \nto aid others in this context-aware rule learning community when developing their own \napproaches for various purposes. We have discussed various issues surrounding the con-\ntext-aware rule learning in terms of time-series modeling, rule discovery based on multi-\ndimensional contexts, and updating the rules over time according to individual’s recent \nbehavioral patterns. In terms of existing research, much focus has been provided on \ntraditional context-aware systems and techniques, with less available work in machine \nlearning rule based context-aware systems for effective decision making in a particular \ndomain. Overall, in this paper we have surveyed previous work and have presented a dis-\ncussion of challenges and future directions for effectively learning context-aware rules \nfrom smartphone data. The domain specific context-aware rules can be used to build \nvarious context-aware systems for the end users to intelligently assist themselves in their \nday-to-day activities. We do believe that our study on smartphone data analytics and \nmachine learning based framework opens a promising path for future research on min-\ning context-aware rules. We also do believe that this study could be used as a reference \nguide for both the academia and industry in the relevant application areas.\n\n\n\nPage 21 of 25Sarker  J Big Data            (2019) 6:95 \n\nAcknowlegements\nThe author would like to thank all the reviewers for their rigorous review and comments. The reviews are detailed and \nhelpful to finalize the manuscript. The author is highly grateful to them. The author also would like to thank the admin-\nistration of Swinburne University of Technology, Melbourne, Australia, for providing the required facilities to do research \nwork and survey in their post-graduate research lab. Finally, the author would like to thank Prof. Jun Han and Dr. Alan \nColman, Swinburne University of Technology, Australia, for their helpful guidance.\n\nAuthors’ contributions\nThis article reviews previous work in the area of smartphone data analytics and presents a discussion of open challenges \nand future directions for context-aware rule learning from smartphone data. The first and corresponding author IHS car-\nried out the conception, survey, analysis and design, and prepare this manuscript as well. The author read and approved \nthe final manuscript.\n\nFunding\nNot applicable.\n\nAvailability of data and materials\nNot applicable.\n\nCompeting interests\nThe author declare that he has no competing interests.\n\nAuthor details\n1 Swinburne University of Technology, Melbourne VIC-3122, Australia. 2 Chittagong University of Engineering and Tech-\nnology, Chittagong, Bangladesh. \n\nReceived: 12 July 2019   Accepted: 10 October 2019\n\nReferences\n 1. El Khaddar MA, Boulmalf M. Smartphone: the ultimate iot and ioe device. In: Smartphones from an applied \n\nresearch perspective, 2017, p. 137.\n 2. Zheng P, Ni LM. Spotlight: the rise of the smart phone. IEEE Distrib Syst Online. 2006;7(3):3.\n 3. International telecommunication union. Measuring the information society. Technical report; 2015. http://www.\n\nitu.int/en/itu-d/stati stics /docum ents/publi catio ns/misr2 015/misr2 015-w5.pdf.\n 4. Google trends. In: https ://trend s.googl e.com/trend s/. 2019.\n 5. Sarker IH. Mobile data science: towards understanding data-driven intelligent mobile applications. EAI endorsed \n\ntransactions on scalable information systems, EAI; 2018.\n 6. Sarker IH. Behavminer: mining user behaviors from mobile phone data for personalized services. In: Proceedings \n\nof the 2018 IEEE international conference on pervasive computing and communications (PerCom 2018), Athens, \nGreece: IEEE; 2018.\n\n 7. Mehrotra A, et al. M. Prefminer: mining user’s preferences for intelligent mobile notification management. In: \nUbiComp, ACM; 2016.\n\n 8. Srinivasan VEA. Mobileminer: mining your frequent patterns on your phone. In: UbiComp, ACM; 2014. p. 389–400.\n 9. Zhu HEA. Mining mobile user preferences for personalized context-aware recommendation. ACM Trans Intell Syst \n\nTechnol. 2014;5(4):58.\n 10. Sarker IH, Colman A, Kabir MA, Han J. Individualized time-series segmentation for mining mobile phone user \n\nbehavior. Comput J. 2017;61:349–68.\n 11. Dourish P. What we talk about when we talk about context. Pers Ubiquitous Comput. 2004;8(1):19–30.\n 12. Schilit BN, Theimer MM. Disseminating active map information to mobile hosts. IEEE Netw. 1994;8(5):22–32.\n 13. Brown PJ, Bovey JD, Chen X. Context-aware applications: from the laboratory to the marketplace. IEEE Pers Com-\n\nmun. 1997;4(5):58–64.\n 14. Ryan N, Pascoe J, Morse D. Enhanced reality fieldwork: the context aware archaeological assistant. Bar Int Ser. \n\n1999;750:269–74.\n 15. Brown PJ. The stick-e document: a framework for creating context-aware applications. Electron Publ. \n\n1995;8:259–72.\n 16. Franklin D, Flaschbart J. All gadget and no representation makes jack a dull environment. In: Proceedings of the \n\nAAAI 1998 spring symposium on intelligent environments, 1998. p. 155–60.\n 17. Ward A, Jones A, Hopper A. A new location technique for the active office. IEEE Pers Commun. 1997;4(5):42–7.\n 18. Hull R, Neaves P, Bedford-Roberts J. Towards situated computing. In: Wearable computers, 1997. Digest of papers., \n\nfirst international symposium On, IEEE; 1997. p. 146–53.\n 19. Rodden T, Cheverst K, Davies K, Dix A. Exploiting context in hci design for mobile systems. In: Workshop on Human \n\nComputer Interaction with Mobile Devices, Glasgow; 1998. p. 21–2.\n 20. Schilit B, Adams N, Want R. Context-aware computing applications. In: Mobile computing systems and applica-\n\ntions, 1994. WMCSA 1994. First workshop On, IEEE; 1994. p. 85–90.\n 21. Dey AK. Understanding and using context. Pers Ubiquitous Comput. 2001;5(1):4–7.\n 22. Cao L. Data science: a comprehensive overview. ACM Comput Surv. 2017;50(3):43.\n 23. Bell S, McDiarmid A. Nodobo: mobile phone as a software sensor for social network research. In: Vehicular technol-\n\nogy conference IEEE; 2011.\n\nhttp://www.itu.int/en/itu-d/statistics/documents/publications/misr2015/misr2015-w5.pdf\nhttp://www.itu.int/en/itu-d/statistics/documents/publications/misr2015/misr2015-w5.pdf\nhttps://trends.google.com/trends/\n\n\nPage 22 of 25Sarker  J Big Data            (2019) 6:95 \n\n 24. Pielot M. Large-scale evaluation of call-availability prediction. In: Proceedings of the international joint conference \non pervasive and ubiquitous computing, ACM; 2014. p. 933–37\n\n 25. Eagle N, Pentland AS. Reality mining: sensing complex social systems. Pers Ubiquitous Comput. 2006;10(4):255–68.\n 26. Sarker IH, Colman A, Kabir MA, Han J. Behavior-oriented time segmentation for mining individualized rules of \n\nmobile phone users. In: Data science and advanced analytics (DSAA), 2016 IEEE international conference On, IEEE; \n2016. p. 488–97.\n\n 27. Sarker IH, Kabir MA, Colman A, Han J. Designing architecture of a rule-based system for managing phone call \ninterruptions. In: Proceedings of the 2017 ACM international joint conference on pervasive and ubiquitous \ncomputing and proceedings of the 2017 ACM international symposium on wearable computers, ACM; 2017. p. \n898–903.\n\n 28. Sarker IH, Kabir MA, Colman A, Han J. Evidence-based behavioral model for calendar schedules of individual \nmobile phone users. In: Data science and advanced analytics (DSAA), 2016 IEEE international conference On, IEEE; \n2016. p. 584–93.\n\n 29. Sarker IH. Understanding the role of data-centric social context in personalized mobile applications. EAI endorsed \ntransactions on context-aware systems and applications. EAI; 2018.\n\n 30. Sarker IH, Colman A, Kabir MA, Han J. Phone call log as a context source to modeling individual user behavior. In: \nProceedings of the 2016 ACM international joint conference on pervasive and ubiquitous computing: adjunct, \nACM; 2016. pp. 630–4.\n\n 31. Union IT. Itu internet report. 2006.\n 32. Almeida TA, Hidalgo JMG, Yamakami A. Contributions to the study of sms spam filtering: new collection and \n\nresults. In: Proceedings of the 11th ACM symposium on document engineering, ACM; 2011. p. 259–62.\n 33. Fischer JE, Yee N, Bellotti V, Good N, Benford S, Greenhalgh C. Effects of content and time of delivery on receptivity \n\nto mobile interruptions. In: Proceedings of the 12th international conference on human computer interaction \nwith mobile devices and services, ACM; 2010. p. 103–12.\n\n 34. Sarker IH, Salah K. Appspred: predicting context-aware smartphone apps using random forest learning. Internet of \nThings; 2019.\n\n 35. Kim J, Mielikäinen T. Conditional log-linear models for mobile application usage prediction. In: Machine learning \nand knowledge discovery in databases. p. 672–87. Berlin: Springer; 2014.\n\n 36. Liao Z-X, Pan Y-C, Peng W-C, Lei P-R. On mining mobile apps usage behavior for predicting apps usage in smart-\nphones. In: Proceedings of the 22nd international conference on information & knowledge management, ACM; \n2013. p. 609–18.\n\n 37. Zhu H, Chen E, Xiong H, Cao H, Tian J. Mobile app classification with enriched contextual information. IEEE Trans \nMob Comput. 2014;13(7):1550–63.\n\n 38. Halvey Mea. Time-based segmentation of log data for user navigation prediction in personalization. In: Web intel-\nligence., IEEE; 2005. p. 636–40.\n\n 39. Halvey M, Keane MT, Smyth B. Time based patterns in mobile-internet surfing. In: Proceedings of the SIGCHI \nconference on human factors in computing systems, ACM; 2006. p. 31–4.\n\n 40. Bordino I, Donato D. Extracting interesting association rules from toolbar data. In: International conference on \ninformation and knowledge management, ACM; 2012.\n\n 41. Paireekreng W, Rapeepisarn K, Wong KW. Time-based personalised mobile game downloading. In: Transactions on \nedutainment II. p. 59–69, 2009.\n\n 42. Rawassizadeh R, Tomitsch M, Wac K, Tjoa AM. Ubiqlog: a generic mobile phone-based life-log framework. Pers \nUbiquitous Comput. 2013;17(4):621–37.\n\n 43. Gandhi S, Oates T, Boedihardjo A, Chen C, Lin J, Senin P, Frankenstein S, Wang X. A generative model for time series \ndiscretization based on multiple normal distributions. In: Proceedings of the 8th workshop on Ph. D. workshop in \ninformation and knowledge management, ACM; 2015. p. 19–25.\n\n 44. Farrahi K, Gatica-Perez D. A probabilistic approach to mining mobile phone data sequences. Pers Ubiquitous \nComput. 2014;18(1):223–38.\n\n 45. Zhang G, Liu X, Yang Y. Time-series pattern based effective noise generation for privacy protection on cloud. IEEE \nTrans Comput. 2015;64(5):1456–69.\n\n 46. Song Y, Ma H, Wang H, Wang K. Exploring and exploiting user search behavior on mobile and tablet devices to \nimprove search relevance. In: Proceedings of the 22nd international conference on world wide web, international \nworld wide web conferences steering committee; 2013. p. 1201–12.\n\n 47. Rawassizadeh R, Momeni E, Dobbins C, Gharibshah J, Pazzani M. Scalable daily human behavioral pattern mining \nfrom multivariate temporal data. IEEE Trans Knowl Data Eng. 2016;28(11):3098–112.\n\n 48. Mukherji A, et al. M. Adding intelligence to your mobile device via on-device sequential pattern mining. In: Ubi-\nComp : Adjunct.\n\n 49. Bayir MA, Demirbas M, Cosar A. A web-based personalized mobility service for smartphone applications. Comput \nJ. 2010;54(5):800–14.\n\n 50. Jayarajah K. Kauffman R. Misra A. Exploring variety seeking behavior in mobile users. In: Proceedings of the inter-\nnational joint conference on pervasive and ubiquitous computing, Seattle, WA, USA, 13–17 September, p. 385–90. \nACM, New York, USA; 2014.\n\n 51. Do T-M-T, Gatica-Perez D. By their apps you shall understand them: mining large-scale patterns of mobile phone \nusage. In: Proceedings of the international conference on mobile and ubiquitous multimedia, Limassol, Cyprus, \n1–3 December, 27. ACM, New York, USA; 2010.\n\n 52. Xu Y, Lin M, Lu H, Cardone G, Lane N, Chen Z, Campbell A, Choudhury T. Preference, context and communities: \na multi-faceted approach to predicting smartphone app usage patterns. In: Proceedings of the international \nsymposium on wearable computers, Zurich, Switzerland, 8–12 September, p. 69–76. ACM, New York, USA; 2013.\n\n 53. Oulasvirta A, Rattenbury T, Ma L, Raita E. Habits make smartphone use more pervasive. Pers Ubiquitous Comput. \n2012;16(1):105–14.\n\n\n\nPage 23 of 25Sarker  J Big Data            (2019) 6:95 \n\n 54. Yu K, Zhang B, Zhu H, Cao H, Tian J. Towards personalized context-aware recommendation by mining context logs \nthrough topic models. In: Proceedings of the Pacific-Asia conference on knowledge discovery and data mining, \nKuala Lumpur, Malaysia, May 29–June 01, p. 431–43. Springer-Verlag Berlin, Heidelberg; 2012.\n\n 55. Naboulsi D, Stanica R, Fiore M. Classifying call profiles in large-scale mobile traffic datasets. In: INFOCOM, 2014 \nProceedings IEEE, IEEE; 2014; p. 1806–14.\n\n 56. Dashdorj Z, Serafini L. Semantic enrichment of mobile phone data records. In: International conference on mobile \nand ubiquitous multimedia. ACM; 2013.\n\n 57. Shin D, Lee J-w, Yeon J, Lee S-g. Context-aware recommendation by aggregating user context. In: Commerce and \nenterprise computing, 2009. CEC’09. IEEE conference On, IEEE; 2009. p. 423–30.\n\n 58. Farrahi K, Gatica-Perez D. Probabilistic mining of socio-geographic routines from mobile phone data. IEEE J Sel Top \nSignal Process. 2010;4(4):746–55.\n\n 59. Sarker IH, Colman A, Han J, Kayes A, Watters P. Calbehav: A machine learning based personalized calendar behav-\nioral model using time-series smartphone data. Comput J 2019;1–16.\n\n 60. Ozer Mea. Predicting the location and time of mobile phone users by using sequential pattern mining techniques. \nComput J. 2016;59(6):908–22.\n\n 61. Do TMT, Gatica-Perez D. Where and what: using smartphones to predict next locations and applications in daily \nlife. Pervasive Mob Comput. 2014;12:79–91.\n\n 62. Farrahi K, Gatica-Perez D. What did you do today?: discovering daily routines from large-scale mobile data. In: \nProceedings of the international conference on multimedia, Vancouver, British Columbia, Canada, 26-31 October, \np. 849–52. ACM, New York, USA; 2008.\n\n 63. Karatzoglou A, Baltrunas L, Church K, Böhmer M. Climbing the app wall: enabling mobile app discovery through \ncontext-aware recommendations. In: Proceedings of the international conference on information and knowledge \nmanagement, Maui, Hawaii, USA, 29 October–02 November, p. 2527–30. ACM, New York, USA; 2012.\n\n 64. Phithakkitnukoon S, Horanont T. Identifying human daily activity pattern using mobile phone data. In: Human \nbehavior understanding. Berlin: Springer; 2010.\n\n 65. Khalil A, Connelly K. Improving cell phone awareness by using calendar information. In: Human-computer interac-\ntion. Berlin: Springer; 2005. p. 588–600.\n\n 66. Dekel A, Nacht D, Kirkpatrick S. Minimizing mobile phone disruption via smart profile management. In: Proceed-\nings of the 11th international conference on human-computer interaction with mobile devices and services, \nACM; 2009. p. 43.\n\n 67. Zulkernain S, et al. A mobile intelligent interruption management system. J Univ Comput Sci. \n2010;16(15):2060–80.\n\n 68. Seo S-s, Kwon A, Kang J-M, Strassner J, Hong JW-K. Pyp: design and implementation of a context-aware configura-\ntion manager for smartphones. In: SmartApps’ 11; 2011.\n\n 69. Shokoohi-Yekta M, Chen Y, Campana B, Hu B, Zakaria J, Keogh E. Discovery of meaningful rules in time series. In: \nProceedings of the ACM SIGKDD international conference on knowledge discovery and data mining, Sydney, \nNSW, Australia, 10–13 August, p. 1085–94. ACM, New York, USA; 2015.\n\n 70. Hartono RN, Pears R, Kasabov N, Worner SP. Extracting temporal knowledge from time series: a case study in \necological data. In: Proceedings of the international joint conference on neural networks, Beijing, China, 6–11 July, \np. 4237–43. IEEE Computer Society, Washington, DC, USA; 2014.\n\n 71. Keogh E, Chu S, Hart D, Pazzani M. Segmenting time series: a survey and novel approach. Data Min Time Ser \nDatabases. 2004;57:1–22.\n\n 72. Das G, Lin K-I, Mannila H, Renganathan G, Smyth P. Rule discovery from time series. KDD. 1998;98:16–22.\n 73. Lu EH-C, Tseng VS, Philip SY. Mining cluster-based temporal mobile sequential patterns in location-based service \n\nenvironments. IEEE Trans Knowl Data Eng. 2011;23(6):914–27.\n 74. Kandasamy K, Kumar CS. Modified pso based optimal time interval identification for predicting mobile user \n\nbehaviour in location based services. Indian J Sci Technol. 2015;8(S7):185–93.\n 75. Xu R, Wunsch D. Survey of clustering algorithms. IEEE Trans Neural Netw. 2005;16(3):645–78.\n 76. MacQueen J. Some methods for classification and analysis of multivariate observations. In: Fifth Berkeley sympo-\n\nsium on mathematical statistics and probability, vol. 1; 1967.\n 77. Rokach L. A survey of clustering algorithms. In: Data mining and knowledge discovery handbook. Berlin: Springer; \n\n2010. p. 269–98.\n 78. Sneath PH. The application of computers to taxonomy. J Gen Microbiol. 1957;17(1):201–26.\n 79. Sorensen T. Method of establishing groups of equal amplitude in plant sociology based on similarity of species. \n\nBiol Skr. 1948;5:1–34.\n 80. Agrawal R, et al. A. Fast algorithms for mining association rules. In: VLDB; 1994, vol. 1215, p. 487–99.\n 81. Quinlan JR. C4.5: Programs for machine learning. Machine learning; 1993.\n 82. Flach PA, Lachiche N. Confirmation-guided discovery of first-order rules with tertius. Mach Learn. \n\n2001;42(1–2):61–95.\n 83. Houtsma M, Swami A. Set-oriented mining for association rules in relational databases. In: Data engineering, 1995. \n\nProceedings of the eleventh international conference On, IEEE; 1995. p. 25–33.\n 84. Ma BLWHY. Integrating classification and association rule mining. In: Proceedings of the fourth international \n\nconference on knowledge discovery and data mining; 1998.\n 85. Han J, Pei J, Yin Y. Mining frequent patterns without candidate generation. In: ACM Sigmod Record, vol. 29, ACM; \n\n2000. p. 1–12.\n 86. Freitas AA. Understanding the crucial differences between classification and discovery of association rules: a posi-\n\ntion paper. ACM SIGKDD Explor Newslett. 2000;2(1):65–9.\n 87. Fournier-Viger P et al. Mining top-k non-redundant association rules. In: Methodologies for intelligent systems. \n\nBerlin: Springer; 2012.\n 88. Bouker S, Saidi R, Yahia SB, Nguifo EM. Ranking and selecting association rules based on dominance relationship. \n\nIn: Tools with artificial intelligence (ICTAI), 2012 IEEE 24th international conference On, vol. 1, IEEE; 2012. p. 658–65.\n\n\n\nPage 24 of 25Sarker  J Big Data            (2019) 6:95 \n\n 89. Witten IH, Frank E. Data mining: practical machine learning tools and techniques. Burlington: Morgan Kaufmann; \n2005.\n\n 90. Holte RC. Very simple classification rules perform well on most commonly used datasets. Mach Learn. \n1993;11(1):63–90.\n\n 91. Witten IH, Frank E, Trigg LE, Hall MA, Holmes G, Cunningham SJ. Weka: practical machine learning tools and tech-\nniques with java implementations. 1999.\n\n 92. Frank E, Witten IH. Generating accurate rule sets without global optimization. 1998.\n 93. Sheng S, Ling CX. Hybrid cost-sensitive decision tree, knowledge discovery in databases. In: PKDD 2005, Proceed-\n\nings of 9th European conference on principles and practice of knowledge discovery in databases. Lecture notes in \ncomputer science, vol. 3721, 2005.\n\n 94. Quinlan JR. Induction of decision trees. Mach Learn. 1986;1(1):81–106.\n 95. Wu X, Kumar V, Quinlan JR, Ghosh J, Yang Q, Motoda H, McLachlan GJ, Ng A, Liu B, Philip SY, et al. Top 10 algo-\n\nrithms in data mining. Knowl Inf Syst. 2008;14(1):1–37.\n 96. Wu C-C, Chen Y-L, Liu Y-H, Yang X-Y. Decision tree induction with a constrained number of leaf nodes. Appl Intell. \n\n2016;45(3):673–85.\n 97. Hong J, Suh E-H, Kim J, Kim S. Context-aware system for proactive personalized service based on context history. \n\nExpert Syst Appl. 2009;36(4):7448–57.\n 98. Lee W-P. Deploying personalized mobile services in an agent-based environment. Expert Syst Appl. \n\n2007;32(4):1194–207.\n 99. Sarker IH. A machine learning based robust prediction model for real-life mobile phone data. Internet Things. \n\n2019;5:180–93.\n 100. Sarker IH, Kabir MA, Colman A, Han J. An improved naive bayes classifier-based noise detection technique for clas-\n\nsifying user phone call behavior; 2017.\n 101. Geng L, Hamilton HJ. Interestingness measures for data mining: a survey. ACM Comput Surv. 2006;38(3):9.\n 102. Ordonez C. Comparing association rules and decision trees for disease prediction. In: Proceedings of the interna-\n\ntional workshop on healthcare information and knowledge management, ACM; 2006. p. 17–24.\n 103. Sarker IH. Research issues in mining user behavioral rules for context-aware intelligent mobile applications. Iran J \n\nComput Sci. 2019;2(1):41–51.\n 104. Cheung DW, Han J, Ng VT, Wong C. Maintenance of discovered association rules in large databases: an incremen-\n\ntal updating technique. In: Data engineering, 1996. Proceedings of the twelfth international conference On, IEEE; \n1996. p. 106–14.\n\n 105. Cheung DW-L, Lee SD, Kao B, et al. A general incremental technique for maintaining discovered association rules. \nIn: DASFAA, vol. 6, 1997. p. 185–94.\n\n 106. Xu B, Yi T, Wu F, Chen Z. An incremental updating algorithm for mining association rules. J Electron. \n2002;19(4):403–7.\n\n 107. Thomas S, Bodagala S, Alsabti K, Ranka S. An efficient algorithm for the incremental updation of association rules \nin large databases. In: KDD, 1997. p. 263–6.\n\n 108. Zhang Z, Li Y, Chen W, Min F. A three-way decision approach to incremental frequent itemsets mining. J Inform \nComput Sci. 2014;11(10):3399–410.\n\n 109. Li Y, Zhang Z-H, Chen W-B, Min F. Tdup: an approach to incremental mining of frequent itemsets with three-way-\ndecision pattern updating. Int J Mach Learn Cybern. 2015;8:441–53.\n\n 110. Yao Y. An outline of a theory of three-way decisions. In: International conference on rough sets and current trends \nin computing, Springer; 2012. p. 1–17.\n\n 111. Amornchewin R, Kreesuradej W. Mining dynamic databases using probability-based incremental association rule \ndiscovery algorithm. J Univ Comput Sci. 2009;15(12):2409–28.\n\n 112. Thusaranon P, Kreesuradej W. A probability-based incremental association rule discovery algorithm for record \ninsertion and deletion. Artif Life Robot. 2015;20(2):115–23.\n\n 113. Lee Sea. An adaptive speed-call list algorithm and its evaluation with esm. In: Human factors in computing sys-\ntems. ACM; 2010.\n\n 114. Barzaiq OO, Loke SW. Adapting the mobile phone for task efficiency: the case of predicting outgoing calls using \nfrequency and regularity of historical calls. Pers Ubiquitous Comput. 2011;15(8):857–70.\n\n 115. Phithakkitnukoon S, Dantu R. Adequacy of data for characterizing caller behavior. In: Proceedings of KDD inter. \nWorkshop on social network mining and analysis (SNAKDD 2008). Citeseer; 2008.\n\n 116. Phithakkitnukoon SEA. Behavior-based adaptive call predictor. ACM Trans Auton Adapt Syst. 2011;6(3):21.\n 117. Bergman O, Komninos A, Liarokapis D, Clarke J. You never call: demoting unused contacts on mobile phones \n\nusing dmtr. Pers Ubiquitous Comput. 2012;16(6):757–66.\n 118. Stefanis V, Plessas A, Komninos A, Garofalakis J. Frequency and recency context for the management and retrieval \n\nof personal information on mobile devices. Pervasive Mob Comput. 2014;15:100–12.\n 119. Sarker IH, Salim FD. Mining user behavioral rules from smartphone data through association analysis. In: Proceed-\n\nings of the 22nd Pacific-Asia conference on knowledge discovery and data mining (PAKDD), Melbourne, Australia, \nSpringer; 2018. p. 450–61.\n\n 120. Sarker IH, Colman A, Han J. Recencyminer: mining recency-based personalized behavior from contextual smart-\nphone data. J Big Data. 2019;6(1):49.\n\n 121. Grosan C, Abraham A. Rule-based expert systems. In: Intelligent systems. Berlin: Springer; 2011; p. 149–85.\n 122. Chang Y-J, Tang JC. Investigating mobile users’ ringer mode usage and attentiveness and responsiveness to com-\n\nmunication. In: Proceedings of the international conference on human-computer interaction with mobile devices \nand services, Copenhagen, Denmark, 24–27 August, p. 6–15. ACM, New York, USA; 2015.\n\n 123. Pejovic Vea. Interruptme: designing intelligent prompting mechanisms for pervasive applications. In: UbiComp, \nACM; 2014. p. 897–908.\n\n 124. Spira JB, Feintuch JB. The cost of not paying attention: how interruptions impact knowledge worker productivity. \nReport from Basex; 2005.\n\n\n\nPage 25 of 25Sarker  J Big Data            (2019) 6:95 \n\n 125. Bureau of labor statistics. http://www.bls.gov.\n 126. Kabir MAEA. User-centric social context information management: an ontology-based approach and platform. \n\nPers Ubiquitous Comput. 2014;18(5):1061–83.\n 127. Sahami Shirazi A, Henze N, Dingler T, Pielot M, Weber D, Schmidt A. Large-scale assessment of mobile notifications. \n\nIn: Proceedings of the SIGCHI conference on human factors in computing systems, ACM; 2014. p. 3055–64.\n 128. Iqbal ST, Horvitz E. Notifications and awareness: a field study of alert usage and preferences. In: Proceedings of the \n\n2010 ACM conference on computer supported cooperative work, ACM; 2010. p. 27–30.\n 129. Kanjo E, Kuss DJ, Ang CS. Notimind: utilizing responses to smart phone notifications as affective sensors. IEEE \n\nAccess. 2017;5:22023–35.\n 130. Turner LD, Allen SM, Whitaker RM. Push or delay? decomposing smartphone notification response behaviour. In: \n\nHuman behavior understanding, Berlin: Springer; 2015. p. 69–83.\n 131. Lu J, Wu D, Mao M, Wang W, Zhang G. Recommender system application developments: a survey. Decis Support \n\nSyst. 2015;74:12–32.\n 132. Bobadilla J, Ortega F, Hernando A, Gutiérrez A. Recommender systems survey. Knowl Based Syst. 2013;46:109–32.\n 133. Kim K-j, Ahn H, Jeong S. Context-aware recommender systems using data mining techniques. In: Proceedings of \n\nworld academy of science, engineering and technology, vol. 64, 2010. p. 357–62.\n 134. Liu Q, Ge Y, Li Z, Chen E, Xiong H. Personalized travel package recommendation. In: Data mining (ICDM), 2011 IEEE \n\n11th international conference On, IEEE; 2011. p. 407–16.\n 135. Ge Y, Liu Q. Xiong H, Tuzhilin A, Chen J. Cost-aware travel tour recommendation. In: Proceedings of the 17th ACM \n\nSIGKDD international conference on knowledge discovery and data mining, ACM; 2011. p. 983–91.\n 136. Park M-H, Hong J-H, Cho S-B. Location-based recommendation system using bayesian user’s preference model in \n\nmobile devices. In: International conference on ubiquitous intelligence and computing, Springer; 2007. p. 1130–9.\n 137. Zheng VW, Cao B, Zheng Y, Xie X, Yang Q. Collaborative filtering meets mobile recommendation: a user-centered \n\napproach. In: AAAI, vol. 10, 2010. p. 236–41.\n 138. World tourism organization, unwto. http://www2.unwto .org/.\n 139. Abbaspour R, Samadzadegan F. Building a context-aware mobile tourist guide system base on a service oriented \n\narchitecture. Int Arch Photogramm Remote Sens Spatial Inform Sci. 2008;37:871–4.\n 140. Pashtan A, Blattler R, Andi AH, Scheuermann P. Catis: a context-aware tourist information system, 2003.\n 141. Williams P, Soares C, Gilbert JE. A clustering rule-based approach to predictive modeling. In: Proceedings of the \n\n48th annual Southeast regional conference, ACM; 2010. p. 45.\n 142. Plessas A, Stefanis V, Komninos A, Garofalakis J. Field evaluation of context aware adaptive interfaces for efficient \n\nmobile contact retrieval. Pervasive Mob Comput. 2017;35:51–64.\n 143. Phithakkitnukoon S, Dantu R. Towards ubiquitous computing with call prediction. ACM SIGMOB Mob Comput \n\nCommun Rev. 2011;15(1):52–64.\n 144. Baeza-Yates R, Jiang D, Silvestri F, Harrison B. Predicting the next app that you are going to use. In: Proceedings of \n\nthe 8th ACM international conference on web search and data mining, ACM; 2015. p. 285–94.\n 145. Zhu H, Cao H, Chen E, Xiong H, Tian J. Exploiting enriched contextual information for mobile app classification. In: \n\nProceedings of the 21st ACM international conference on information and knowledge management, ACM; 2012. \np. 1617–21.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nhttp://www.bls.gov\nhttp://www2.unwto.org/\n\n\tContext-aware rule learning from smartphone data: survey, challenges and future directions\n\tAbstract \n\tIntroduction\n\tBackground: contexts and smartphone data\n\tCharacteristics of contexts\n\tContextual smartphone data\n\n\tContext-aware rule learning strategies\n\tModeling time-series smartphone data\n\tStatic segmentation\n\tDynamic segmentation\n\n\tRule discovery\n\tAssociation rules\n\tClassification rules\n\n\tIncremental learning and updating\n\n\tChallenges and future directions\n\tSuggested machine learning based framework\n\tContext-aware rule based applications\n\tConclusion\n\tAcknowlegements\n\tReferences\n\n\n\n\n"
    },
    {
      "@search.score": 1,
      "content": "\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 \nDOI 10.1186/s40467-015-0033-9\n\nRESEARCH Open Access\n\nExtraction methods for uncertain inference\nrules by ant colony optimization\nLing Chen, Yun Sun* and Yuanguo Zhu\n\n*Correspondence:\nchinalsy_881220@163.com\nSchool of Science, Nanjing\nUniversity of Science and\nTechnology, Nanjing 210094, China\n\nAbstract\n\nIn recent years, the research on data mining methods has received increasing\nattention. In this paper, we design an uncertain system with the extracted uncertain\ninference rules to solve the classification problems in data mining. And then, two\nextraction methods integrated with ant colony optimization are proposed for the\ngeneration of the uncertain inference rules. Finally, two applications are given to verify\nthe effectiveness and superiority of the proposed methods.\n\nKeywords: Uncertain inference rule; Uncertain system; Ant colony optimization\nalgorithm; Rules extraction; Data classification\n\nIntroduction\nNowadays, databases and computer networks, coupled with the use of advanced auto-\nmated data generation and collection tools, are widely used in many different fields such\nas finance, E-commerce, logistics, etc. As a result, the amount of data that people have\nto deal with is dramatically increasing. People hope to carry out scientific research, busi-\nness decision, or business management on the basis of the analysis of the existing data.\nHowever, the current data analysis tools have difficulty in processing the data in depth.\nTo compensate for this deficiency, there come the data mining techniques. Data mining is\nthe computational process of discovering some interesting, potentially useful patterns in\nlarge data sets. Those patterns can be concepts, rules, laws, and modes. The overall goal\nof data mining is to extract information from a data set and transform it into an under-\nstandable structure for further use. Data mining helps us to discover valuable information\nand knowledge. Data mining is applied tomany fields in reality. There are many successful\nexamples [1] of data mining in business and science research. For instance, data mining is\nwidely used in financial data analysis, telecommunication, retail, and biomedical research.\nTherefore, the study of data mining technology has an important practical significance.\nThe main jobs of data mining are data description, data classification, data dependency,\n\ndata compartment analysis, data regression, data aggregate, and data prediction. What\ndata classification does is to find a couple of models or functions that can accurately\ndescribe the characteristics of the data sets. Then, we can identify the categories of the\npreviously unknown data. After obtaining themodels or functions from the set of training\ndata with data mining algorithms, we use many methods to describe the output such as\nclassification rules (if-then), decision trees, mathematical formula, and neutral network.\n\n© 2015 Chen et al.; licensee Springer. This is an Open Access article distributed under the terms of the Creative Commons\nAttribution License (http://creativecommons.org/licenses/by/4.0), which permits unrestricted use, distribution, and reproduction\nin any medium, provided the original work is properly credited.\n\nmailto: chinalsy_881220@163.com\nhttp://creativecommons.org/licenses/by/4.0\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 2 of 19\n\nThere are a variety of approaches in data mining. For mining objects in different fields,\nmany different specifiedmethods are invented. The approaches we usually used are statis-\ntical methods, machine learning methods, and modern intelligent optimization methods.\nThe statistical methods are very effective methods from the start. In addition, many other\ndata mining methods are invented based on the statistical methods. When dealing with\nclassification problems, Bayesian classification and Bayesian belief network are important\nclassification methods that based on the statistical principle. Machine learning methods\nare mainly used to solve the conceptual learning, pattern classification, and pattern clus-\ntering problems. The core content of machine learning is inductive learning. And there\nalready exist a number of mature technology methods, such as decision tree method for\nclassification problems. Decision trees method is one of the most popular classification\nmethods. The early decision trees algorithm is ID3 method. Later, based on ID3, many\nalgorithms such as C4.5 method [2] are proposed. Besides, there are some variants of the\ndecision trees algorithm including incremental tree structure ID4, ID5, and expandable\ntree structure SLIQ for massive data set.\nIn recent years, intelligent optimization algorithms are widely applied into data min-\n\ning. Neutral network is a simulation model for complex system with nonlinear relations.\nIt is very suitable to deal with complex nonlinear relations in spatial data. Researchers\nhave already proposed different network models to realize the clustering, classification,\nregression, and pattern recognition of the data. Furthermore, many evolution algorithms\nsuch as simulated annealing algorithm are introduced into neutral network algorithm\nas the optimization strategies. Genetic algorithm is a global search algorithm that sim-\nulates the biological evolution and genetic mechanism. It plays an important role in\noptimization and classification machine learning. Mixed algorithms of genetic algorithm\nand other algorithms, such as decision trees, neutral network, have been applied to the\ndata mining technology. Ant colony optimization algorithm is a bionic optimization algo-\nrithm that simulates the behavior of the ants. Based on that, a data mining technique\nant-miner [3] was invented. And Herrera [4] applied it to fuzzy rules learning. How-\never, ant colony optimization algorithm has some weakness such as slow convergence,\nrandom initial solutions. For this reason, some improved ant colony optimization algo-\nrithms are proposed. Zhu proposed an improved ant colony optimization algorithm\n(ACOA) [5] and a mutation ant colony optimization algorithm (MACO) [6] to speed up\nthe algorithms and avoid the solutions getting stuck in local optimums. Hybrid genetic\nant colony optimization [7] and hybrid particle swarm ant colony optimization algo-\nrithm [8] significantly improve the performance of the original ant colony optimization\nalgorithm.\nThe real world is so complex that human being may face different types of indetermi-\n\nnacy everyday. To get a better understanding of the real world, many mathematical tools\nare created. One of them is probability theory which is used to model indeterminacy from\nsamples. However, in many cases, no samples are available to estimate a probability distri-\nbution. In this situation, we have no choice but to invite some domain experts to evaluate\nthe belief degree that each event may occur. We cannot use probability theory to deal\nwith belief degree since human beings usually overweight unlikely events which makes\nthe belief degrees deviate far from the frequency. In view of this, Liu [9] founded uncer-\ntainty theory based on normality axiom, duality axiom, subadditivity axiom, and product\nmeasure axiom. It has become a powerful mathematical tool dealing with indeterminacy.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 3 of 19\n\nMany researchers have done a lot of theoretical work related to uncertainty theory. In\n2008, Liu [10] presented the uncertain differential equation. Later, the existence and\nuniqueness theorem was given [11]. And the stability of uncertain differential equation\nwas discussed [12,13]. Also, some analysis and numerical methods for solving uncertain\ndifferential equation were proposed. With uncertain differential equation describing the\nevolution of the system, we may solve some practical problems. Peng and Yao [14] stud-\nied an option pricing models for stocks. Zhu [15] proposed an uncertain optimal control\nmodel in 2010.\nIn [16,17], Liu proposed and studied the uncertain systems based on the concepts of\n\nuncertain sets, membership functions, and uncertain inference rules. An uncertain sys-\ntem is a function from its inputs to outputs based on the uncertain inference rule. Usually,\nan uncertain system consists of five parts: inputs, rule-base, uncertain inference rules,\nexpected value operator, and outputs. Following that, Gao et al. [18] generalized uncertain\ninference rules and described uncertain systems with them. Peng and Chen [19] proved\nthat uncertain systems are universal approximator and then demonstrated that the uncer-\ntain controller is a reasonable tool. Gao [20] designed an uncertain inference controller\nthat successfully balanced an inverted pendulum with 5 × 5 if-then rules. What is more\nimportant is that this uncertain inference controller has a good ability of robustness.\nOn the basis of uncertainty theory, we consider two extraction methods for uncertain\n\ninference rules by ant colony optimization algorithm. In the next section, we review the\nant colony optimization algorithm and give some basic concepts about uncertain sets.\nThen, we formulate a model to extract inference rules based on data set. And then, we\npropose an extraction method for uncertain inference rules by ant colony optimization\nalgorithm with a mutation operation. Finally, we combine the ant colony optimiza-\ntion algorithm with simulated annealing algorithm to speed up the extraction method.\nIn the last section, we discuss two typical classification problems in data mining with\nour results.\n\nPreliminary\nIn this section, we review the ant colony optimization algorithm. And then, we give some\nbasic concepts on uncertainty sets.\n\nAnt colony optimization algorithm\n\nAnt colony optimization algorithm, initiated by Dorigo, is a heuristic optimization\napproach. It simulates the behavior of real ants when they forage for food which relies on\nthe pheromone communication. In ant colony optimization algorithm, each path of artifi-\ncial ants walking from the food sources to the nest is a candidate solution to the problem.\nWhen walking on the path, the ants will release pheromone which evaporates over time.\nAnd the artificial ants will lay down more pheromone on the path corresponding to the\nbetter solution. While one ant has many paths to go, it will make a choice according to\nthe amount of the pheromone on the paths. The more pheromone there is on the path,\nthe better the solution is. As a result, bad paths will disappear since the pheromone evap-\norates over time. And good paths will be reserved since ants walking on it increases the\npheromone levels. Finally, one path which is used by most of the ants is left. Then, the\noptimal solution to the problem is obtained.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 4 of 19\n\nConsider the following optimization problem:\n\n⎧⎪⎪⎪⎨\n⎪⎪⎪⎩\nmin f (x)\ns.t.\n\ng(x) ≥ 0\nx ∈ D\n\n(1)\n\nwhere x is the decision variable in the domain D. And f (x) is the objective function while\ng(x) is the constraint function.\nWe can use ant colony optimization algorithm to obtain the optimal solution to the\n\nproblem (1). The parameters in the algorithm are initial pheromone τ0, ant transfer prob-\nability p, number of ants M, pheromone evaporation rate ρ, and number of iterations T .\nThe procedures are as follows.\n\nStep 1 Randomly generate a feasible solution x0 and set optimal solution s = x0. Initialize\nall pheromone trails with the same pheromone level τ0. Set k ← 0.\nStep 2 The artificial ant generates a walking path x in some probability p according to\n\nthe pheromone trails. If x ∈ D, then go to Step 3; otherwise, repeat Step 2 until x ∈ D.\nStep 3 Repeat Step 2 until for each ant and generate M feasible solutions. Let sk be the\n\nbest solution in this iteration.\nStep 4 If f (sk) < f (s), then s ← sk and update the pheromone trails according to the\n\noptimal solution in the current iteration.\nStep 5 If k < T , then k ← k + 1 and go to Step 2; otherwise, terminate.\nStep 6 Report the optimal solution.\n\nUncertain set\n\nLet � be a nonempty set and L be σ -algebra over �. Each � ∈ L is called an event. For\nany �, M{�} ∈ [0, 1]. The set function M defined on L is called an uncertain measure\nif it satisfies the following three axiom: M{�} = 1; M{�} + M{�c} = 1 for any � ∈ L;\nM\n\n{⋃∞\ni=1 �i\n\n} ≤ ∑∞\ni=1M{�i} for all �1,�2, · · · ∈ L. Then, the triplet (�,L,M) is called\n\nan uncertainty space [9]. The product uncertain measureM is an uncertain measure sat-\nisfying M\n\n{∏∞\ni=1 �k\n\n} = ∞∧\ni=1\n\nMk{�k}, where �k are arbitrarily chosen events from Lk for\nk = 1, 2, · · · , respectively.\n\nDefinition 1. [16] An uncertain set is a function ξ from an uncertainty space (�,L,M)\n\nto a collection of sets of real numbers such that both {B ⊂ ξ} and {ξ ⊂ B} are events for\nany Borel set B.\n\nExample 1. Take (�,L,M) to be {γ1, γ2, γ3} with power set L. Then, the set-valued\nfunction\n\nξ(γ ) =\n\n⎧⎪⎪⎨\n⎪⎪⎩\n[ 1, 3] , if γ = γ1\n\n[ 2, 4] , if γ = γ2\n\n[ 3, 5] , if γ = γ3\n\nis an uncertain set on (�,L,M).\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 5 of 19\n\nDefinition 2. [16] The uncertain sets ξ1, ξ2, ξ3, · · · , ξn are said to be independent if for\nany Borel sets B1,B2,B3, · · · ,Bn, we have\n\nM\n\n{ n⋂\ni=1\n\n(\nξ∗\ni ⊂ Bi\n\n)} =\nn∧\n\ni=1\nM\n\n{\nξ∗\ni ⊂ Bi\n\n}\nand\n\nM\n\n{ n⋃\ni=1\n\n(\nξ∗\ni ⊂ Bi\n\n)} =\nn∨\n\ni=1\nM\n\n{\nξ∗\ni ⊂ Bi\n\n}\n\nwhere ξ∗\ni are arbitrarily chosen from\n\n{\nξi, ξ ci\n\n}\n, i = 1, 2, · · · , n, respectively.\n\nDefinition 3. [21] An uncertain set ξ is said to have a membership function μ if for any\nBorel set B of real numbers, we have\n\nM{B ⊂ ξ} = inf\nx∈Bμ(x),M{ξ ⊂ B} = 1 − sup\n\nx∈Bc\nμ(x).\n\nThe above equations will be called measures inversion formulas.\n\nRemark 1. When an uncertain set ξ does have a membership function μ, it follows\nfrom the first measure inversion formula that\n\nμ(x) = M{x ∈ ξ}.\n\nExample 2. An uncertain set ξ is called triangular if it has a membership function\n\nμ(x) =\n⎧⎨\n⎩\n\nx−a\nb−a , a ≤ x ≤ b\n\nx−c\nb−c , b ≤ x ≤ c\n\n(2)\n\ndenoted by (a, b, c) where a, b, c are real numbers with a < b < c.\n\nDefinition 4. [21]Amembership functionμ is said to be regular if there exists a point x0\nsuch that μ(x0) = 1, and μ(x) is unimodal about the mode x0. That is, μ(x) is increasing\non (−∞, x0] and decreasing on [ x0,+∞).\n\nDefinition 5. [16] Let ξ be an uncertain set. Then, the expected value of ξ is defined by\n\nE[ ξ ]=\n∫ +∞\n\n0\nM{ξ \n r}dr −\n\n∫ 0\n\n−∞\nM{ξ � r}dr\n\nprovided that at least one of the two integrals is finite and\n\nM{ξ \n r} = 1\n2\n(M{ξ ≥ r} + 1 − M{ξ < r}),\n\nM{ξ � r} = 1\n2\n(M{ξ ≤ r} + 1 − M{ξ > r}).\n\nTheorem 1. [13] Let ξ be an uncertain set with regular membership function μ. Then\n\nE[ ξ ]= x0 + 1\n2\n\n∫ +∞\n\nx0\nμ(x)dx − 1\n\n2\n\n∫ x0\n\n−∞\nμ(x)dx, (3)\n\nwhere x0 is a point such that μ(x0) = 1.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 6 of 19\n\nExample 3. Let ξ be a triangular uncertain set denoted by (a, b, c). Then, according to\nTheorem 1, we have\n\nE[ ξ ]= a + 2b + c\n4\n\n.\n\nIn fact, it follows from Equations 2 and 3 that\n\nE[ ξ ] = b + 1\n2\n\n∫ c\n\nb\n\nx − c\nb − c\n\ndx − 1\n2\n\n∫ b\n\na\n\nx − a\nb − a\n\ndx\n\n= b − 1\n4\n(b − c) − 1\n\n4\n(b − a)\n\n= a + 2b + c\n4\n\n.\n\nUncertain inference rule\n\nHere, we introduce concepts of the uncertain inference and uncertain system. Inference\nrules are the key points of the inference systems. In fuzzy systems, CRI approach [22],\nMamdani inference rules [23] and Takagi-Sugeno inference rules [24] are the most com-\nmon used inference rules. Fuzzy if-then inference rules use fuzzy sets to describe the\nantecedents and the consequents. Unlike fuzzy inference, both antecedents and conse-\nquents in uncertain inference are characterized by uncertain sets. Uncertain inference\n[16] is a process of deriving consequences from human knowledge via uncertain set\ntheory. First, we introduce the following inference rule.\n\nInference Rule 1. [16] Let X and Y be two concepts. Assume a rule ‘if X is an uncertain\nset ξ , then Y is an uncertain set η’. From X is a constant a, we infer that Y is an uncertain\nset\n\nη∗ = η|a∈ξ\n\nwhich is the conditional uncertain set of η given a ∈ ξ . The inference rule is represented by\n\nRule: If X is ξ , then Y is η\n\nFrom: X is a constant a\n\nInfer: Y is η∗ = η|a∈ξ\n\nTheorem 2. [16] Let ξ and η be independent uncertain sets with membership functions\nμ and ν, respectively. If ξ∗ is a constant a, then the Inference Rule 1 yields that η∗ has a\nmembership function\n\nν∗(y) =\n\n⎧⎪⎪⎪⎪⎨\n⎪⎪⎪⎪⎩\n\nν(y)\nμ(a) , if ν(y) <\n\nμ(a)\n2\n\nν(y)+μ(a)−1\nμ(a) , if ν(y) > 1 − μ(a)\n\n2\n\n0.5, otherwise.\n\nBased on Inference Rule 1, Gao et al. [18] proposed the multi-input, multi-if-then-rule\ninference rules.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 7 of 19\n\nInference Rule 2. [13] Let X1,X2, · · · ,Xm,Y be concepts. Assume rules ‘if X1 is ξi1\nand · · · and Xm is ξim, then Y is ηi’ for i = 1, 2, · · · , k. From X1 is a constant a1 and · · ·\nand Xm is a constant am, we infer that\n\nη∗ =\nk∑\n\ni=1\n\nci · ηi|(a1∈ξi1)∩(a2∈ξi2)∩···∩(am∈ξim)\n\nc1 + c2 + · · · + ck\n, (4)\n\nwhere the coefficients are determined by\n\nci = M{(a1 ∈ ξi1) ∩ (a2 ∈ ξi2) ∩ · · · ∩ (am ∈ ξim)}\nfor i = 1, 2, · · · , k. The inference rule is represented by\n\nRule 1: If X1 is ξ11 and · · · and Xm is ξ1m, then Y is η1\nRule 2: If X1 is ξ21 and · · · and Xm is ξ2m, then Y is η2\n\n· · ·\nRule k: If X1 is ξk1 and · · · and Xm is ξkm, then Y is ηk\nFrom: X1 is a1 and · · · and Xm is am\nInfer: Y is determined by Eq. (4)\n\nTheorem 3. [13] Assume ξi1, ξi2, · · · , ξim, ηi are independent uncertain sets with mem-\nbership functions μi1,μi2, · · · ,μim, νi, i = 1, 2, · · · , k, respectively. If ξ∗\n\n1 , ξ∗\n2 , · · · , ξ∗\n\nm are\nconstants a1, a2, · · · , am, respectively, then the Inference Rule 2 yields\n\nη∗ =\nk∑\n\ni=1\n\nci · η∗\ni\n\nc1 + c2 + · · · + ck\n\nwhere η∗\ni are uncertain sets whose membership functions are given by\n\nν∗\ni (y) =\n\n⎧⎪⎪⎪⎪⎨\n⎪⎪⎪⎪⎩\n\nνi(y)\nci , if νi(y) < ci\n\n2\n\nνi(y)+ci−1\nμ(a) , if νi(y) > 1 − ci\n\n2\n\n0.5, otherwise\n\nand ci = min\n1≤l≤m\n\nμil(al) are constants.\n\nUncertain system\n\nUncertain system, proposed by Liu [16], is a function from its inputs to outputs based\non the uncertain inference rule. Usually, an uncertain system consists of five parts: inputs\nthat are crisp data to be fed into the uncertain system; a rule-base that contains a set of\nif-then rules provided by the experts; an uncertain inference rule that infers uncertain\nconsequents from the uncertain antecedents; an expected value operator that converts\nthe uncertain consequents to crisp values; and outputs that are crisp data yielded from\nthe expected value operator.\nNow, we consider an uncertain system with m crisp inputs α1,α2, · · · ,αm, and n crisp\n\noutputs β1,β2, · · · ,βn. We have the following if-then rules:\n\nIf X1 is ξ11 and · · · and Xm is ξ1m, then Y1 is η11 and Y2 is η12 and · · · and Yn is η1n\nIf X1 is ξ21 and · · · and Xm is ξ2m, then Y1 is η21 and Y2 is η22 and · · · and Yn is η2n\n\n· · ·\nIf X1 is ξk1 and · · · and Xm is ξkm, then Y1 is ηk1 and Y2 is ηk2 and · · · and Yn is ηkn\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 8 of 19\n\nThus, according to Inference Rule 1 and 2, we can infer that Yj(j = 1, 2, · · · , n) are\n\nη∗\nj =\n\nk∑\ni=1\n\nci · ηij|(a1∈ξi1)∩(a2∈ξi2)∩···∩(am∈ξim)\n\nc1 + c2 + · · · + ck\n,\n\nwhere ci = M{(a1 ∈ ξi1)∩ (a2 ∈ ξi2)∩· · ·∩ (am ∈ ξim)} for i = 1, 2, · · · , k. Then, by using\nthe expected value operator, we obtain\n\nβj = E\n[\nη∗\nj\n\n]\nfor j = 1, 2, · · · , n. Now, we construct a function from crisp inputs α1,α2, · · · ,αm to crisp\noutputs β1,β2, · · · ,βn, i.e.,\n\n(β1,β2, · · · ,βn) = f (α1,α2, · · · ,αm).\n\nThen, we get an uncertain system f. For the uncertain system we proposed, we have the\nfollowing theorem.\n\nTheorem 4. [13] Assume that ξi1, ξi2, · · · , ξim and ηi1, ηi2, · · · , ηin are indepen-\ndent uncertain sets with membership functions μi1,μi2, · · · ,μim, νi1, νi2, · · · , νin, i =\n1, 2, · · · , k, respectively. Then, the uncertain system from α1,α2, · · · ,αm to β1,β2, · · · ,βn is\n\nbj =\nk∑\n\ni=1\n\nci · E[ η∗\nij]\n\nc1 + c2 + · · · + ck\n,\n\nwhere j = 1, 2, · · · , n and η∗\nij are uncertain sets whose membership functions are given by\n\nν∗\nij(y) =\n\n⎧⎪⎪⎪⎪⎨\n⎪⎪⎪⎪⎩\n\nνij(y)\nci , if νij(y) < ci\n\n2\n\nνij(y)+ci−1\nμ(a) , if νij(y) > 1 − ci\n\n2\n\n0.5, otherwise\n\nand ci = min\n1≤l≤m\n\nμil(al) are constants.\n\nNext, we discuss the expected value of a special triangular uncertain set.Without loss of\ngenerality, we assume n = 1. Then the uncertain system proposed in the above becomes:\n\nb =\nk∑\n\ni=1\n\nci · E[ η∗\ni ]\n\nc1 + c2 + · · · + ck\n, (5)\n\nν∗\ni (y) =\n\n⎧⎪⎪⎪⎪⎨\n⎪⎪⎪⎪⎩\n\nνi(y)\nci , if νi(y) < ci\n\n2\n\nνi(y)+ci−1\nμ(a) , if νi(y) > 1 − ci\n\n2\n\n0.5, otherwise,\n\n(6)\n\nci = min\n1≤l≤m\n\nμil(al). (7)\n\nTheorem 5. Assume we have an uncertain system with m inputs and 1 output consist-\ning of k inference rules. The antecedents of the rules are represented by the uncertain sets ξi\nwith membership functions μi1,μi2, · · · ,μim, i = 1, 2, · · · , k. And the consequent is repre-\nsented by an triangular uncertain set ηi = (αi,βi, γi) with a membership function νi, where\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 9 of 19\n\nthe coefficients satisfy\n\nαi + γi = 2βi, i = 1, 2, · · · , k. (8)\n\nWe have\n\nE\n[\nη∗\ni\n] = βi, i = 1, 2, · · · , k.\n\nProof. Given the m input data a1, a2, · · · , am, we can calculate ci from Equation 7.\nThen, we can get the membership functions ν∗\n\ni of the consequence uncertain sets η∗\ni\n\naccording to Equation 6. Next, the computation of the expected value of uncertain\nconsequence breaks into three cases.\nCase 1: Assume ci/2 = 0.5. We can immediately have ν∗\n\ni (y) = νi(y), thus\n\nE[ η∗\ni ]=\n\nαi + 2βi + γi\n4\n\n= βi.\n\nCase 2: Assume ci/2 < 0.5. Let yi11 and yi12\n(\nyi11 < yi12\n\n)\nbe the two points that satisfy\n\nthe equation νi(y) = ci/2. Similarly, yi21 and yi22\n(\nyi21 < yi22\n\n)\nsatisfy the equation νi(y) =\n\n1 − ci/2. Since the membership function of a triangular uncertain set has a symmetry\nproperty, we have\n\nyi11 + yi12 = 2βi, yi21 + yi22 = 2βi. (9)\n\nThen, we can rewrite the membership function of ηi as follows:\n\nν∗\ni =\n\n⎧⎪⎪⎪⎪⎪⎪⎪⎪⎨\n⎪⎪⎪⎪⎪⎪⎪⎪⎩\n\nνi(y)\nci , if αi ≤ y < yi11\n\nνi(y)+ci−1\nci , if yi21 ≤ y < yi22\n\nνi(y)\nci , if yi12 ≤ y < γi\n\n0.5, otherwise.\n\n(10)\n\nAnd ν∗\ni (βi) = 1. Together with Equations 3, 8, and 9, we have\n\nE[ η∗\ni ] = βi + 1\n\n2\n\n(∫ yi22\n\nβi\n\nνi(y) + ci − 1\nci\n\ndy +\n∫ yi12\n\nyi22\n0.5dy +\n\n∫ γi\n\nyi12\n\nνi(y)\nci\n\ndy\n)\n\n−1\n2\n\n(∫ βi\n\nyi21\n\nνi(y) + ci − 1\nci\n\ndy +\n∫ yi21\n\nyi11\n0.5dy +\n\n∫ yi11\n\nαi\n\nνi(y)\nci\n\ndy\n)\n\n= βi + 1\n2\n\n(∫ yi22\n\nβi\n\nνi(y) + ci − 1\nci\n\ndy −\n∫ βi\n\nyi21\n\nνi(y) + ci − 1\nci\n\ndy\n)\n\n+1\n2\n\n(∫ γi\n\nyi12\n\nνi(y)\nci\n\ndy −\n∫ yi11\n\nαi\n\nνi(y)\nci\n\ndy\n)\n\n+1\n2\n\n(∫ yi12\n\nyi22\n0.5dy −\n\n∫ yi21\n\nyi11\n0.5dy\n\n)\n\n= βi.\n\nCase 3: Assume ci > 0.5. Similarly, we have E[ η∗\ni ]= βi. Thus, we have proved the\n\ntheorem.\n\nProblem formulation\nIn this section, we propose an extraction model to obtain uncertain inference rules.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 10 of 19\n\nLet X = (x1, x2, · · · , xn) be the decision vector, which represents a rule base consisting\nof n rules. Each rule has m antecedents which are described by Q uncertain sets and one\nconsequent which is described by R uncertain sets. Each variable xi represents a sequence\nxi1xi2 · · · ximxim+1, where xij ∈ {0, 1, 2, · · · ,Q}(i = 1, 2, · · · , n; j = 1, 2, · · · ,m) represent\nthe antecedents of the inference rule. And xim+1 ∈ {0, 1, 2, · · · ,R}(i = 1, 2, · · · , n) repre-\nsent the consequent. Thus, each variable of decision vector represents one inference rule.\nSome xij = 0 means this antecedent is not included. And some xim+1 = 0 means this\ninference rule will not be included in the rule base. For example, assume that we have one\ninference rule consists of 4 antecedents and 1 consequent. They are described by 5 uncer-\ntain sets which refer to five descriptions: very low, low, medium, high, and very high. We\nuse 1, 2, 3, 4, 5 to denote them. Thus, sequence “23045”, for example, represents the rule:\n“if input 1 is low, input 2 is medium, and input 4 is high, then the output is very high”.\nUncertain systems can be used for classification. But which uncertain system is better\n\ndepends on the rule base. Here, we try to find best rule base by comparing the mean\nabsolute errors of the origin output and the system output. That is,\n\nMAE = 1\nP\n\nP∑\ni=1\n\n|oi − ti|, (11)\n\nwhere P is the number of training data, oi, ti(i = 1, 2, · · · ,P) are the system outputs and\norigin outputs, respectively. If we find the rule base with the least mean absolute error, we\nextract the uncertain inference rules successfully. We can obtain the system outputs by\nEquation 5. However, they may not be integers. To avoid this nonsense, for a classification\nproblem with C classes, we can divide interval that covers all the system outputs into C\nsubintervals. Then, if the output from Equation 5 is in the ith subinterval, we have oi = i.\nThus, we transfer the classification problem to the following optimization model:⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨\n\n⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩\n\nmin\nX\n\nF(X) = MAE\n\ns.t.\nX = (x1, x2, · · · , xn)\nxi = xi1 · · · ximxim+1\nxij ∈ {0, 1, · · · ,Q}\nxim+1 ∈ {0, 1, · · · ,R}\ni = 1, 2, · · · , n\nj = 1, 2, · · · ,m\n\nExtractionmethod for uncertain inference rules withmutations\nIn this section, we propose the extraction method for uncertain inference rules with\nmutations by ant colony optimization algorithm.\nAs stated before, each xi is a sequence of m values in {0, 1, 2, · · · ,Q} and 1 value in\n\n{0, 1, 2, · · · ,R}. Without loss of generality, we set Q = R. Each number in {0, 1, 2, · · · ,Q}\nis a node. Let ants walking across these nodes. Ants choose the next node in probability\nbased on the pheromone levels in the Q + 1 choices at every step. Once ants movem + 1\nsteps, a candidate decision variable is generated. After repeat this process n times, we get\na candidate solution. After all ants finish their walk, update the pheromone trails. Denote\nthe pheromone trail by τi;k,j(t) associated to the node j at step k of xi in iteration t. The\nprocedures are described as follows.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 11 of 19\n\n(1) Initialization: Randomly generate a feasible solutionX0, and set the optimal solution\nX̂ = X0. Set τi;k,j(0) = τ0, i = 1, 2, · · · , n, k = 1, 2, · · · ,m + 1, j = 0, 1, 2, · · · ,Q, where τ0\nis a fixed parameter.\n(2) Ant movement: At each step k after building the sequence xi1xi2 · · · xik , select the\n\nnext node in probability following\n\npk;k+1 = τi;k+1,j(t)\nQ∑\n\nq=0\nτi;k+1,q(t)\n\n. (12)\n\nIn this way, we could get a sequence xi1xi2 · · · xim+1. To speed up the algorithm, wemutate\nthis sequence to get a new candidate sequence. The mutation is made as follows: ran-\ndomly add 1 or subtract 1 to each element xij in the sequence; if the element is 0, the\nmutated element is 1; if the element is Q, the mutated element is Q − 1. Assume X ′ is\nthe mutated solution, if \rF = F(X ′\n\n) − F(X) ≤ 0, then X ← X ′ ; otherwise, keep the\ncurrent solution. If Q is very large, we could repeat this mutation until some termination\ncondition is satisfied.\n(3) Pheromone Update: At each iteration t, let X̂ be the optimal solution found so far\n\nand Xt be the best feasible solution in the current iteration. Assume F(X̂) and F(Xt) are\nthe corresponding objective function values.\n\nIf F(Xt) < F(X̂), then X̂ ← Xt .\nReinforce the pheromone trails on nodes of X̂ and evaporate the pheromone trails on\n\nthe left nodes:\n\nτi;j,k(t) =\n{\n\n(1 − ρ)τi;j,k(t − 1) + ρg(X̂), if (k, j) ∈ X̂\n(1 − ρ)τi;j,k(t − 1), otherwise\n\n(13)\n\nwhere ρ (0 < ρ < 1) is the evaporation rate, g(x)(0 < g(x) < +∞) is a function with that\ng(x) ≥ g(y) if F(x) < F(y), for example, g(x) = L/(|F(x)| + 1) is a function satisfying the\ncondition where L > 0.\n\nLet τ0 be the initial value of pheromone trails, n be the number of decision variables,\nM be the number of ants, ρ be evaporation rate and T be the number of iterations. Now,\nwe summarize the algorithm as follows.\n\nStep 1 Initialize all pheromone trails with the same pheromone level τ0. Randomly\ngenerate a feasible solution X0, and set optimal solution X̂ = X0. Set l ← 0.\nStep 2 Ant movement in probability following Equation 12. Generate a decision variable\n\nxi afterm + 1 steps.\nStep 3 Repeat Step 2 until X = (x1, x2, · · · , xn) is generated; mutate every xi: thus, gen-\n\nerate a new decision vector X ′ = (x′\n1, x\n\n′\n2, · · · , x\n\n′\nn); if \rF = F(X ′\n\n) − F(X) ≤ 0, then\nX ← X ′ .\nStep 4 Repeat Step 2 and Step 3 for allM ants.\nStep 5 Calculate the system outputs by Equation 5. Then, calculate the objective function\n\nvalues for the M candidate solutions by Equation 11. Denote the best solution in this\niteration by Xl.\nStep 6 If F(Xl) < F(X̂), then X̂ ← Xl; update the pheromone trails according to\n\nEquation 13.\nStep 7 l ← l + 1; if l = T , terminate; otherwise, go to Step 2.\nStep 8 Report the optimal solution X̂.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 12 of 19\n\nWith this algorithm above, we obtain an uncertain rule base. Then, we successfully\ndesign an uncertain system and can use it for classification.\n\nExtractionmethod for uncertain inference rules with SA\nIn the previous section, to speed up the algorithm, we introduce a mutation operation.\nHere, we introduce the simulated annealing algorithm as the local search operation.\nSimulated annealing algorithm was initiated by Metropolis in 1953, applied to portfolio\n\noptimization by Kirkpatrick [25] in 1983. The name and inspiration come from anneal-\ning in metallurgy, a technique involving heating and controlled cooling of a material to\nincrease the size of its crystals and reduce their defects. Simulated annealing algorithm is\nexcellent at avoiding getting stuck in local optimums. It has a good robust property and is\nuniversal and easy to implement.\nFor optimization problem (1), we can use simulated annealing algorithm to search for\n\nthe optimal solution. The algorithm is as follows.\n\nStep 1 Randomly generate a initial solution x0; x ← x0; k ← 0; t0 ← tmax(initial\ntemperature);\nStep 2 If the temperature satisfies the inner cycle termination criterion, go to Step 3;\n\notherwise, randomly choose a point x′ in the neighborhood N(x), calculate \rf = f (x′\n) −\n\nf (x). If \rf ≤ 0, then x ← x′ ; otherwise, according to Metropolis acceptance criterion, if\nexp(−\rf /tk) > random(0, 1), then x ← x′ . Repeat Step 2.\nStep 3 tk+1 = d(tk) (temperature decrease); k ← k + 1; if the termination criterion is\n\nsatisfied, stop and report the optimal solution; otherwise, go to Step 2.\n\nIn this section, we combine ant colony optimization algorithm and simulated annealing\nalgorithm. In each iteration of ant colony optimization algorithm, we get a feasible solu-\ntion. Then, we use it as the initial solution of the simulated annealing algorithm to get a\nneighbor solution. This neighbor solution will be accepted in probability. And for each\ndecision vector X = (x1, x2, · · · , xn), xi = xi1xi2 · · · xim+1, we build the neighbor solution\nas follows: for each xi, for some randomly generated p and q (1 ≤ p < q ≤ m), reverse the\norder of the sequence xip · · · xiq, i.e., x′\n\ni = xi1 · · · xip−1xiqxiq−1 · · · xip+1xipxiq+1 · · · xim+1.\nFor example, assume xi is 0123456, p = 2, q = 6, and the neighbor solution x′\n\ni is 0543216.\nIn this way, we obtain a neighbor solution X ′ . If \rF = F(X ′\n\n) − F(X) ≤ 0, X ← X ′ ;\notherwise, if exp(−\rF/tk) > random(0, 1), then X ← X ′ ; otherwise, abandon this neigh-\nbor solution. Still denote the pheromone trail by τi;k,j(t). The procedure are described as\nfollows.\n\n(1) Initialization: Generate a feasible solution X0 randomly and set the optimal solution\nX̂ = X0. Set τi;k,j(0) = τ0, i = 1, 2, · · · , n, k = 1, 2, · · · ,m + 1, j = 0, 1, 2, · · · ,Q, where τ0\nis a fixed parameter.\n(2) Ant movement: At each step k after building the sequence xi1xi2 · · · xik , select the\n\nnext node in probability following Equation 12. In this way, we could get a sequence\nxi1xi2 · · · xim+1. In order to expand the search range, we use simulated annealing algo-\nrithm to search locally around the solution at this step. Assume the neighbor solution is\nX ′ . If \rF = F(X ′\n\n) − F(X) ≤ 0, X ← X ′ ; otherwise, if exp(−\rF/tk) > random(0, 1)\nwhere tk is the current temperature and tk → 0 when k → ∞, then X ← X ′ ; otherwise,\nabandon this neighbor solution and still choose the original feasible solution.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 13 of 19\n\n(3) Pheromone Update: Let X̂ be the optimal solution found so far and Xt be the best\nfeasible solution in the current iteration t. Assume F(X̂) and F(Xt) are the correspond-\ning objective function values. To avoid the optimal solution X̂ getting stuck in local\noptimums, we also use acceptance function here.\n\nIf F(Xt) < F(X̂), then X̂ ← Xt .\nBuild a neighbor solution X̂ ′ .\nIf F(X̂ ′\n\n) ≤ F(X̂), then X̂ ← X̂ ′ ;\nIf F(X̂ ′\n\n) > F(X̂), check the Metropolis acceptance criterion, i.e., if\nexp(−\rF̂/Tt) > random(0, 1), Tt → 0, t → ∞, then X∗ ← X̂ ′ .\n\nReinforce the pheromone trails on the nodes of X̂ andX∗ and evaporate the pheromone\ntrails on the left nodes:\n\nτi;j,k(t) =\n\n⎧⎪⎨\n⎪⎩\n\n(1 − ρ)τi;j,k(t − 1) + ρg(X̂), if (k, j) ∈ X̂\n(1 − ρ)τi;j,k(t − 1) + ρ\n\n2 g(X̂), if (k, j) ∈ X∗\n\n(1 − ρ)τi;j,k(t − 1), otherwise\n(14)\n\nwhere, ρ (0 < ρ < 1) is the evaporate rate, and g(x) (0 < g(x) < +∞) is a function with\nthat g(x) ≥ g(y) if F(x) < F(y). For example, g(x) = L/(|F(x)|+1) is an available function\nif L > 0.\n\nNow, we summarize the algorithm as follows.\n\nStep 1 Initialize all pheromone trails with the same pheromone level τ0. Randomly\ngenerate a feasible solution X0, and set optimal solution X̂ = X0. Set t ← 0.\nStep 2 Ant movement in probability following Equation 12. Generate a decision variable\n\nxi afterm + 1 steps.\nStep 3 Repeat Step 2 until decision vector X = (x1, x2, · · · , xn) is generated. Build the\n\nneighbor solution X ′ . If \rF = F(X ′\n) − F(X) ≤ 0, X ← X ′ ; otherwise, if exp(−\rF/tk) >\n\nrandom(0, 1)where tk is the current temperature and tk → 0 when k → ∞, thenX ← X ′ .\nStep 4 Repeat Step 2 and Step 3 until all ants finish their walk, and generate M candidate\n\nsolutions.\nStep 5 Calculate the system outputs by Equation 5. Then, calculate the objective function\n\nvalues for the M candidate solutions by Equation 11. Denote the best solution in this\niteration by Xt .\nStep 6 If F(Xt) < F(X̂), then X̂ ← Xt . Build the neighbor solution of X̂, which is denoted\n\nby X̂ ′ . If \rF̂ = F(X̂ ′\n) − F(X̂) ≤ 0, then X̂ ← X̂ ′ ; otherwise, if Metropolis acceptance\n\ncriterion is satisfied, i.e., if exp(−\rF̂/Tt) > random(0, 1),Tt → 0, t → ∞, thenX∗ ← X̂ ′ .\nStep 7 Update the pheromone trails according to Equation 14.\nStep 8 t ← t + 1; if t = T, terminate; otherwise, go to Step 2.\nStep 9 Report the optimal solution X̂.\n\nTable 1 Parameters\n\nap bp cp\n\np = 1 0.5 1.01 1.52\n\np = 2 1.7 2.74 4.48\n\np = 3 5 6.07 7.14\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 14 of 19\n\nFigure 1 Results of method A.\n\nExperiments\nIn this section, we use our two extraction methods to extract uncertain inference rules.\nAnd then use the uncertain systems to solve some classification problems.We applied our\nmethods to the IRIS [26] classification problem and the Wisconsin Breast Cancer (WBC)\n[27] classification problem.\n\nIRIS classification\n\nIRIS data set is the typical date set in data classification. It contains 150 instances of 3\nclasses, which are Setosa, Versicolor, and Virginica. Each class has 50 instances. Each\ninstance has 4 attributes which are sepal length (SL), sepal width (SW), petal length (PL),\n\nFigure 2 Results of method B.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 15 of 19\n\nTable 2 Accuracy comparison\n\nMethod Paper Accuracy rate (%)\n\nMethod A This paper 97.33\n\nMethod B This paper 97.5\n\nC4.5 [2] 94.0\n\nACOA [5] 96.6\n\nMACO [6] 95.53\n\nHNFQ [28] 98.67\n\nTable 3 IRIS classification rules extracted bymethod A\n\nIF THEN\n\nSL SW PL PW Class\n\n1 3 1 3 1\n\n1 0 1 1 1\n\n1 2 3 2 1\n\n1 1 2 1 2\n\n2 1 0 3 2\n\n3 2 0 2 3\n\n1 1 3 3 3\n\nTable 4 IRIS classification rules extracted bymethod B\n\nIF THEN\n\nSL SW PL PW Class\n\n3 2 3 1 2\n\n1 1 0 0 2\n\n0 2 1 1 3\n\n0 1 1 3 1\n\n1 1 3 3 2\n\n1 1 3 1 1\n\n2 1 1 2 1\n\nTable 5 Parameters\n\nap bp cp\n\np = 1 0.3 1.01 1.72\n\np = 2 2 6.07 10.14\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 16 of 19\n\nFigure 3 Results of method A.\n\nand petal width (PW). They are described by 3 uncertain sets: low (1), medium (2), and\nhigh (3). The membership functions are\n\nμq(x) = exp\n(\n\n− (x − Vq)2\n\n2β2\n\n)\n,\n\nwhere x is the input, β = 0.618 and Vq = q−1\n2 , q = 1, 2, 3. Based on these 4 attributes,\n\nwe try to infer which class does the instance belong to. We use 3 triangular uncertain\nsets ηp = (ap, bp, cp) (p = 1, 2, 3) to describe the possible classes (class 1: Setosa; class 2:\nVersicolor; class 3: Virginica). And the parameters ap, bp, cp ∈ R are listed in Table 1.\nFirst, we normalize the data to [0, 1] to simplify the computation. IRIS data set is our\n\ntraining set while it is also used for testing. Then, we set maximum number of rules n =\n10, number of ants M = 10, evaporate rate ρ = 0.3, and number of iterations T = 300.\nEach algorithm runs ten times. The results are in Figures 1 and 2. Denote the extraction\n\nFigure 4 Results of method B.\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 17 of 19\n\nTable 6 Accuracy rate comparison\n\nMethod Paper Accuracy rate (%)\n\nMethod A This paper 98.3\n\nMethod B This paper 98.33\n\nC4.5 [2] 94.25\n\nACOA [5] 97.91\n\nMACO [6] 97.07\n\nFMM [29] 97.86\n\nmethod with mutation by A and the method with SA by B. It can be seen that the method\nA converges fast at about 120th iteration. And method B converges a little slower at about\n150th iteration.\nThen, we can classify the IRIS data with the uncertain systems we introduced. We\n\nfind the average accuracy rates of the two methods are 97.33% and 97.5%, respectively.\nComparison with other methods are listed in Table 2.\nList the rule bases we get with the highest accuracy rates (98.0% and 98.67%, respec-\n\ntively) in Tables 3 and 4. Note that although the maximum number of rules is 10, the final\nrule bases we obtain has only 7 rules.\n\nWisconsin Breast Cancer classification\n\nWisconsin Breast Cancer data set is a common medical date set. It contains 699 instances\nof 2 classes, which are sick and healthy. Two hundred forty-one instances are sick and 458\ninstances are healthy. Each instances has 9 attributes, which are clump thickness (CT),\nuniformity of cell size (UCS), uniformity of cell shape (UCCS), marginal adhesion (MA),\nsingle epithelial cell size (SPCS), bare nuclei (BN), bland chromatin (BC), normal nucleoli\n(NN), and mitoses (MT). They are described by 5 uncertain sets: very low (1), low (2),\nmedium (3), high (4), and very high (5). The membership functions are\n\nμq(x) = exp\n(\n\n− (x − Vq)2\n\n2β2\n\n)\n,\n\nwhere x is the input, β = 0.4247, and Vq = q−1\n2 , q = 1, 2, 3, 4, 5. Based on these attributes,\n\nwe diagnose whether one instance is sick or not. We use 2 triangular uncertain sets\nηp = (ap, bp, cp) (p = 1, 2) to describe the possible classes (sick and healthy). And the\nparameters ap, bp, cp ∈ R are listed in Table 5.\n\nTable 7WBC classification rules extracted bymethod A\n\nIF THEN\n\nCT UCS UCCS MA SPCS BN BC NN MT Class\n\n1 5 0 3 2 0 4 2 1 2\n\n1 2 1 1 4 4 2 1 0 1\n\n1 3 5 2 3 2 1 1 4 2\n\n1 3 4 2 3 1 2 2 1 1\n\n2 4 4 1 1 2 4 5 1 2\n\n3 3 4 5 4 3 2 4 4 2\n\n5 2 4 0 3 0 0 2 1 1\n\n2 4 4 1 1 2 4 5 1 1\n\n2 4 2 3 5 3 2 5 5 2\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 18 of 19\n\nTable 8WBC classification rules extracted bymethod B\n\nIF THEN\n\nCT UCS UCCS MA SPCS BN BC NN MT Class\n\n5 3 3 3 3 2 3 2 4 2\n\n0 0 0 0 0 0 0 4 0 1\n\n4 4 4 4 0 1 1 1 4 2\n\n1 4 4 1 1 2 1 5 1 2\n\n1 1 1 2 0 3 5 5 5 2\n\n0 3 0 0 0 0 0 1 2 1\n\nFirst, we normalize the data to [0, 1] to simplify the computation. The first 460 instances\nare used for training while the left 239 instances are used for testing. Then, we set max-\nimum number of rules n = 10, number of ants M = 20, evaporate rate ρ = 0.3, and\nnumber of iterations T = 200. Each algorithm runs ten times. The results are in Figures 3\nand 4. We still find that method A converges faster than method B. Method A stabilizes\nat about 50th iteration while method B stabilizes until about 80th iteration.\nThen, we test the uncertain systems we get with the later 239 instances. We find the\n\naverage accuracy rates of the two methods on the training set are 96.0% and 96.26%,\nrespectively. Using the uncertain system with the highest accuracy rate of each method\non the test set, we find the accuracy rates are 98.37% and 98.33%. Comparison with other\nmethods are listed in Table 6.\nThe rule base with the highest accuracy rates (98.37% and 98.33%, respectively) on the\n\ntest set are listed in Tables 7 and 8. Method A gives us a rule base of 9 rules, and method\nB provides a rule base of 6 rules.\nWe apply our two extraction methods to the classification problems of IRIS data set\n\nand WBC data set. Compare our results with other researchers’ work, we can find that\nboth methods have higher accuracy rate than ACOA and MACO in two classification\nproblems. And for IRIS data set, accuracy rates of method A and B are lower than HNFQ\nbut higher than C4.5. For WBC data set, their accuracy rates are higher than C4.5 and\nFMM.\n\nConclusions\nIn this paper, we designed an uncertain system for data classification. And we proposed\ntwo extraction methods for uncertain inference rules by using ant colony optimization\nalgorithm. Then, we applied our methods to IRIS classification problem and WBC clas-\nsification problem. Our methods are shown to be superior in accuracy to some existing\nmethods.\n\nAcknowledgements\nThis work is supported by the National Natural Science Foundation of China (No.61273009).\n\nReceived: 14 December 2014 Accepted: 20 April 2015\n\nReferences\n1. Kantardzic, M: Data Mining: Concepts, Models, Methods, and Algorithms. 2nd ed. Wiley, Hoboken (2011)\n2. Quinlan, JR: Improved use of continuous attributes in C4.5. J. Artif. Intell. Res. 4(1), 77–90 (1996)\n3. Parpinelli, RS, Lopes, HS, Freitas, AA: Data mining with an ant colony optimization algorithm. IEEE Trans. Evolut.\n\nComput. 6(4), 321–332 (2002)\n4. Casillas, J, Cordón, O, Herrera, F: Learning fuzzy rules using ant colony optimization algorithms. In: Proceedings of\n\nthe 2nd International Workshop on Ant Algorithms: From Ant Colonies to Artificial Ants, pp. 13–21, Brussels, (2000)\n\n\n\nChen et al. Journal of Uncertainty Analysis and Applications  (2015) 3:9 Page 19 of 19\n\n5. Zhu, Y: Ant colony optimization-based hybrid intelligent algorithms. World J. Modell. Simul. 2(5), 283–289 (2006)\n6. Zhu, Y: An intelligent algorithm: MACO for continuous optimization models. J. Intell. Fuzzy Syst. 24, 31–36 (2013)\n7. Lee, Z, Su, S, Chuang, C, Liu, K: Genetic algorithm with ant colony optimization (GA-ACO) for multiple sequence\n\nalignment. Appl. Soft Comput. 8(1), 55–78 (2008)\n8. Shelokar, PS, Siarry, P, Jayaraman, VK, Kulkarni, BD: Particle swarm and ant colony algorithms hybridized for improved\n\ncontinuous optimization. Appl. Math. Comput. 188(1), 129–142 (2007)\n9. Liu, B: Uncertainty Theory. 2nd ed. Springer, Berlin (2007)\n10. Liu, B: Fuzzy process, hybrid process and uncertain process. J. Uncertain Syst. 2(1), 3–16 (2008)\n11. Chen, X, Liu, B: Existence and uniqueness theorem for uncertain differential equations. Fuzzy Optimization Decis.\n\nMak. 9(1), 69–81 (2010)\n12. Liu, B: Some research problems in uncertainty theory. J. Uncertain Syst. 3(1), 3–10 (2009)\n13. Liu, B: Uncertainty Theory: A Branch of Mathematics for Modeling Human Uncertainty. Springer, Berlin (2010)\n14. Peng, J, Yao, K: A new option pricing model for stocks in uncertainty markets. Int. J. Oper. Res. 8(2), 18–26 (2011)\n15. Zhu, Y: Uncertain optimal control with application to a portfolio selection model. Cybern. Syst. 41(7), 535–547 (2010)\n16. Liu, B: Uncertain set theory and uncertain inference rule with application to uncertain control. J. Uncertain Syst. 4(2),\n\n83–98 (2010)\n17. Liu, B: Uncertain logic for modeling human language. J. Uncertain Syst. 5(1), 3–20 (2011)\n18. Gao, X, Gao, Y, Ralescu, DA: On Liu’s inference rule for uncertain systems. Int. J. Uncertain. Fuzz. Knowledged-Based\n\nSyst. 18(1), 1–11 (2010)\n19. Peng, Z, Chen, X: Uncertain systems are universal approximators. J. Uncertainty Anal. Appl. 2, Article, 13 (2014)\n20. Gao, Y: Uncertain inference control for balancing inverted pendulum. Fuzzy Optimization Decis. Mak. 11(4), 481–492\n\n(2012)\n21. Liu, B: Membership functions and operational law of uncertain sets. Fuzzy Optimization Decis. Mak. 11(4), 387–410\n\n(2012)\n22. Zadeh, LA: Outline of a new approach to the analysis of complex systems and decision processes. IEEE Trans. Syst.\n\nMan Cybern. 3(1), 28–44 (1973)\n23. Mamdani, EH: Applications of fuzzy algorithms for control of a simple dynamic plant. Proc. Institution Electr. Eng.\n\nControl Sci. 121(12), 1585–1588 (1974)\n24. Takagi, K, Sugeno, M: Fuzzy identification of system and its applications to modeling and control. IEEE Trans. Syst.\n\nMan Cybern. 15(1), 116–132 (1985)\n25. Kirkpatrick, S, Gelatt, CD, Vecchi, MP: Optimization by simmulated annealing. Science. 220(4598), 671–680 (1983)\n26. Iris dataset (1936). https://archive.ics.uci.edu/ml/datasets/Iris\n27. Wisconsin Breast Cancer Dataset (1992). https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)\n28. de Souza, FJ, Vellasco, M, Pacheco MA: Hierarchical neuro-fuzzy quadtree models. Fuzzy Sets Syst. 130(2), 189–205\n\n(2002)\n29. Gabrys, B, Bargiela, A: General fuzzy min-max neural network for clustering and classification. IEEE Trans. Neural\n\nNetwor. 11(3), 769–783 (2000)\n\nSubmit your manuscript to a \njournal and benefi t from:\n\n7 Convenient online submission\n\n7 Rigorous peer review\n\n7 Immediate publication on acceptance\n\n7 Open access: articles freely available online\n\n7 High visibility within the fi eld\n\n7 Retaining the copyright to your article\n\n    Submit your next manuscript at 7 springeropen.com\n\nhttps://archive.ics.uci.edu/ml/datasets/Iris\nhttps://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)\n\n\tAbstract\n\tKeywords\n\n\tIntroduction\n\tPreliminary\n\tAnt colony optimization algorithm\n\tUncertain set\n\tUncertain inference rule\n\tUncertain system\n\n\tProblem formulation\n\tExtraction method for uncertain inference rules with mutations\n\tExtraction method for uncertain inference rules with SA\n\tExperiments\n\tIRIS classification\n\tWisconsin Breast Cancer classification\n\n\tConclusions\n\tAcknowledgements\n\tReferences\n\n"
    }
  ]
}
```